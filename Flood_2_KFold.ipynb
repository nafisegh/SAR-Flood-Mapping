{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "040b1b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate, Dropout, GlobalAveragePooling2D, MaxPooling2D, Concatenate, Flatten, Dense\n",
    "from tensorflow.keras.applications import vgg16\n",
    "\n",
    "from tensorflow.keras.applications import resnet\n",
    "\n",
    "from tensorflow.keras import applications\n",
    "\n",
    "from tensorflow.keras import layers,losses,optimizers,metrics,Model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "132d4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81742456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_data(train_resampled,label,batch_size):\n",
    "    \n",
    "        \n",
    "    def data_augmentation(data,image_count=1):\n",
    "\n",
    "        augmented_images=[]\n",
    "        \n",
    "        patch_size=512\n",
    "\n",
    "        datagen=ImageDataGenerator(horizontal_flip=True)\n",
    "\n",
    "        it=datagen.flow(np.expand_dims(data,axis=0),batch_size=1)\n",
    "\n",
    "        for i in range(image_count):\n",
    "    \n",
    "            augmented_images.append(np.squeeze(it.next(),axis=0))\n",
    "        \n",
    "        return(np.stack(augmented_images)) \n",
    "    \n",
    "    anchors,refs,events=np.zeros((batch_size,patch_size,patch_size,3)),np.zeros((batch_size,patch_size,patch_size,3)),np.zeros((batch_size,patch_size,patch_size,3))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    " \n",
    "            index=random.randint(0,train_resampled.shape[0]-1)\n",
    "\n",
    "            #anchor=data_augmentation(positive)\n",
    "\n",
    "            ref=train_resampled[index,:,:,0:3]\n",
    "            \n",
    "            event=train_resampled[index,:,:,3:]\n",
    "\n",
    "            anchor=data_augmentation(ref)\n",
    "\n",
    "            anchors[i],refs[i],events[i]=anchor,ref,event\n",
    "    \n",
    "    return [anchors,refs,events]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ca7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Contrastive_Loss(margin,embedding_dim,tav): #tav:maximum acceptable distance between similar samples\n",
    "    \n",
    "    def get_loss(output_true,output_pred):\n",
    "        \n",
    "        output_true=tf.cast(output_true,tf.float32)\n",
    "        \n",
    "        input1=output_pred[:,:embedding_dim]\n",
    "        \n",
    "        input2=output_pred[:,embedding_dim:2*embedding_dim]\n",
    "        \n",
    "        d=tf.reduce_sum(tf.square(input1-input2))\n",
    "        \n",
    "        return(output_true*tf.maximum(margin-d,0)+(1-output_true)*tf.maximum(d-tav,0))  \n",
    "    \n",
    "    return get_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d79d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Generator(train_resampled,label,batch_size,embedding_dim,mode):\n",
    "    \n",
    "    while True:\n",
    "    \n",
    "        x=create_batch_data(train_resampled,label,batch_size)\n",
    "        \n",
    "        if mode=='triplet':\n",
    "        \n",
    "            y=np.zeros((batch_size,3*embedding_dim))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            x=x[1:]\n",
    "            \n",
    "            y=np.zeros((batch_size,2*embedding_dim))\n",
    "        \n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a9846a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 512, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 512, 512, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 512, 512, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 256, 256, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 256, 256, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 256, 256, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 128, 128, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 128, 128, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 128, 128, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 128, 128, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 64, 64, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 64, 64, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 64, 64, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 64, 64, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 32, 32, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 131072)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               67109376  \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82,024,256\n",
      "Trainable params: 82,022,720\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "patch_size=512\n",
    "\n",
    "#cnn=vgg16.VGG16(weights='imagenet',input_shape=(patch_size,patch_size)+(3,),include_top=False)\n",
    "\n",
    "flatten=layers.Flatten()(cnn.output)\n",
    "\n",
    "#tc1 = layers.Conv2DTranspose(256, 17, activation='relu', data_format='channels_last')(cnn.output)\n",
    "\n",
    "#tc1=layers.BatchNormalization()(tc1)\n",
    "\n",
    "dense_1=layers.Dense(512,activation='relu')(flatten)\n",
    "\n",
    "dense_1=layers.BatchNormalization()(dense_1)\n",
    "\n",
    "dense_2=layers.Dense(256,activation='relu')(dense_1)\n",
    "\n",
    "#tc2=layers.Conv2DTranspose(64, 97, activation='relu',data_format='channels_last')(tc1)\n",
    "\n",
    "#tc2=layers.BatchNormalization()(tc2)\n",
    "\n",
    "dense_2=layers.BatchNormalization()(dense_2)\n",
    "\n",
    "#output=layers.Conv2DTranspose(3,129, activation='relu', data_format='channels_last')(tc2)\n",
    "\n",
    "output=layers.Dense(256)(dense_2)\n",
    "\n",
    "\n",
    "\n",
    "embedding=Model(cnn.input,output,name='Embedding')\n",
    "\n",
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b05406a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Creating Siamese Network Architecture With Triplets Of Anchor, Positive, and Negative Image Patches as Input\n",
    "\n",
    "anchor_input=layers.Input(name='anchor',shape=(patch_size,patch_size)+(3,))\n",
    "\n",
    "positive_input=layers.Input(name='positive',shape=(patch_size,patch_size)+(3,))\n",
    "\n",
    "negative_input=layers.Input(name='negative',shape=(patch_size,patch_size)+(3,))\n",
    "\n",
    "embedding_anchor=embedding(anchor_input)\n",
    "embedding_positive=embedding(positive_input)\n",
    "embedding_negative=embedding(negative_input)\n",
    "\n",
    "output=layers.concatenate([embedding_anchor,embedding_positive,embedding_negative])\n",
    "#output=layers.concatenate([embedding_positive,embedding_negative])\n",
    "\n",
    "model=Model([anchor_input,positive_input,negative_input],output)\n",
    "#model=Model([positive_input,negative_input],output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "884e1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Triplet Loss\n",
    "\n",
    "def Triplet_Loss(margin, embedding_dim):\n",
    "    \n",
    "    def get_loss(output_true,output_pred):\n",
    "        \n",
    "        anchor_output=output_pred[:,:embedding_dim]\n",
    "        \n",
    "        positive_output=output_pred[:,embedding_dim:2*embedding_dim]\n",
    "        \n",
    "        negative_output=output_pred[:,2*embedding_dim:]\n",
    "        \n",
    "        dp=tf.reduce_sum(tf.square(anchor_output-positive_output),axis=1)\n",
    "        \n",
    "        dn=tf.reduce_sum(tf.square(anchor_output-negative_output),axis=1)\n",
    "        \n",
    "        return tf.maximum(dp-dn+margin,0)\n",
    "        \n",
    "    return get_loss    \n",
    "\n",
    "\n",
    "### Contrastive Loss\n",
    "\n",
    "def Contrastive_Loss(margin,embedding_dim,tav): #tav:maximum acceptable distance between similar samples\n",
    "    \n",
    "    def get_loss(output_true,output_pred):\n",
    "\n",
    "        \n",
    "        output_true=tf.cast(output_true,tf.float32)\n",
    "        \n",
    "        input1=output_pred[:,:embedding_dim]\n",
    "        \n",
    "        input2=output_pred[:,embedding_dim:2*embedding_dim]\n",
    "        \n",
    "        d=tf.reduce_sum(tf.square(input1-input2))\n",
    "        \n",
    "        return(output_true*tf.maximum(margin-d,0)+(1-output_true)*tf.maximum(d-tav,0))  \n",
    "    \n",
    "    return get_loss\n",
    "\n",
    "\n",
    "### Weighted Double Margin Contrastive Loss (WDMCL)\n",
    "\n",
    "def Weighted_Double_Margin_Contrastive_Loss(embedding_dim,w1,w2 ,m1=0.9,m2=0.45):\n",
    "    \n",
    "    def get_loss(output_true,output_pred):\n",
    "\n",
    "        \n",
    "        input1=output_pred[:,:embedding_dim]\n",
    "    \n",
    "        input2=output_pred[:,embedding_dim:2*embedding_dim]\n",
    "        \n",
    "        d=tf.reduce_sum(tf.square(input1-input2))\n",
    "        \n",
    "        return(0.5*((w1*(1-output_true)*(tf.maximum(d-m1,0))**2)+(w2*output_true*(tf.maximum(m2-d,0))**2)))\n",
    "    \n",
    "    return(get_loss)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b707abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Generator(train_resampled,label,batch_size,embedding_dim,mode):\n",
    "    \n",
    "    while True:\n",
    "    \n",
    "        x=create_batch_data(train_resampled,label,batch_size)\n",
    "        \n",
    "        if mode=='triplet':\n",
    "        \n",
    "            y=np.zeros((batch_size,3*embedding_dim))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            x=x[1:]\n",
    "            \n",
    "            y=np.zeros((batch_size,2*embedding_dim))\n",
    "        \n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e3be786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fitting The Siamese Model and Setting Training Parameters\n",
    "\n",
    "#train_resampled__s,_,train_label_s,_=train_test_split(train_resampled_,train_label,stratify=train_label,test_size=0.96,random_state=1)\n",
    "\n",
    "#val_resampled__s,_,val_label_s,_=train_test_split(val_resampled,val_label,stratify=val_label,test_size=0.96,random_state=1)\n",
    "\n",
    "batch_size,embedding_dim, epochs=5, 256, 200\n",
    "\n",
    "lr_schedule=tf.keras.optimizers.schedules.ExponentialDecay(0.001,decay_rate=0.8,decay_steps=10000)\n",
    "\n",
    "#model.compile(loss=Triplet_Loss(margin=0.9, embedding_dim=embedding_dim),optimizer=Adam(learning_rate=lr_schedule))\n",
    "\n",
    "        \n",
    "#w1=1/(len(train_label_s[train_label_s==0])) # weight for unchanged pixels\n",
    "        \n",
    "#w2=1/(len(train_label_s[train_label_s==1])) # weight for changed pixels\n",
    "\n",
    "#w1=1/(len(train_label[train_label==0])) # weight for unchanged pixels\n",
    "        \n",
    "#w2=1/(len(train_label[train_label==1])) # weight for changed pixels\n",
    "\n",
    "\n",
    "#Weighted_Double_Margin_Contrastive_Loss(embedding_dim,w1,w2,m1=0.9,m2=0.45)\n",
    "\n",
    "#Contrastive_Loss(embedding_dim=embedding_dim,margin=0.01,tav=0.01)\n",
    "\n",
    "model.compile(loss=Triplet_Loss(margin=0.9, embedding_dim=embedding_dim),optimizer=Adam(learning_rate=lr_schedule))\n",
    "\n",
    "es=tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10,min_delta=1e-3,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c54b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "62/62 [==============================] - ETA: 0s - loss: 3.7129 "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "for i in range(1,6):\n",
    "\n",
    "    imgs = np.load(f'G:/sen11_cross_validation_bitemporal_numpy_image/fold_{i}/train/fold_{i}.npy')\n",
    "    \n",
    "    masks = np.load(f'G:/sen11_cross_validation_bitemporal_numpy_mask/fold_{i}/train/fold_{i}.npy')\n",
    "\n",
    "    imgs_valid = np.load(f'G:/sen11_cross_validation_bitemporal_numpy_image/fold_{i}/valid/fold_{i}.npy')\n",
    "    \n",
    "    masks_valid = np.load(f'G:/sen11_cross_validation_bitemporal_numpy_mask/fold_{i}/valid/fold_{i}.npy')\n",
    "    \n",
    "    mch=tf.keras.callbacks.ModelCheckpoint(filepath=f'G:/sen1flood11_triplet_loss_fold_{i}.h5',save_best_only=True)\n",
    "\n",
    "    \n",
    "    data_valid=create_batch_data(imgs_valid,masks_valid, imgs_valid.shape[0])\n",
    "    \n",
    "    #data_valid = data_valid[1:] #omitting the anchor \n",
    "    \n",
    "    history=model.fit(Data_Generator(imgs,masks,batch_size,embedding_dim,'triplet'),steps_per_epoch=int(imgs.shape[0]/batch_size),epochs=epochs,callbacks=[es,mch],validation_data=(data_valid,masks_valid))\n",
    "    \n",
    "    ##history=model.fit(Data_Generator(train_resampled,train_label,batch_size,'contrastive'),steps_per_epoch=int(train_resampled.shape[0]/batch_size),epochs=epochs,callbacks=[es,mch],validation_data=(val_data,val_label))\n",
    "    \n",
    "    \n",
    "    model.save(f'G:/sen1flood11_triplet_loss_fold_{i}_last_epoch.h5')\n",
    "\n",
    "\n",
    "    with open(f'G:/sen1flood11_triplet_loss_fold_{i}.pckl', 'wb') as hist:\n",
    "        \n",
    "        pickle.dump(history.history,hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71af180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tensorflow.keras.layers import LeakyReLU, Conv2DTranspose\n",
    "\n",
    "from tensorflow.keras import layers,Model\n",
    "\n",
    "embedding_dim=256\n",
    "\n",
    "patch_size=512\n",
    "\n",
    "input_layer=layers.Input(shape=(2*embedding_dim,))\n",
    "\n",
    "#flatten1=layers.Flatten()(input_layer)\n",
    "\n",
    "#dense1=layers.Dense(256)(flatten1)\n",
    "\n",
    "input_layer_r=tensorflow.reshape(input_layer, [-1,16,16,2])\n",
    "\n",
    "tc1 = layers.Conv2DTranspose(256, 17, data_format='channels_last')(input_layer_r)\n",
    "\n",
    "LR1=LeakyReLU(alpha=0.1)(tc1)\n",
    "\n",
    "#dense2=layers.Dense(128)(LR1)\n",
    "\n",
    "tc2 = layers.Conv2DTranspose(128, 33, data_format='channels_last')(LR1)\n",
    "\n",
    "LR2=LeakyReLU(alpha=0.1)(tc2)\n",
    "\n",
    "drop1=layers.Dropout(0.1)(LR2)\n",
    "\n",
    "#dense3=layers.Dense(128)(drop1)\n",
    "\n",
    "tc3 = layers.Conv2DTranspose(64, 65, data_format='channels_last')(drop1)\n",
    "\n",
    "LR3=LeakyReLU(alpha=0.1)(tc3)\n",
    "\n",
    "drop2=layers.Dropout(0.1)(LR3)\n",
    "\n",
    "#dense4=layers.Dense(64)(drop2)\n",
    "\n",
    "tc4 = layers.Conv2DTranspose(32, 129, data_format='channels_last')(drop2)\n",
    "\n",
    "LR4=LeakyReLU(alpha=0.1)(tc4)\n",
    "\n",
    "#dense5=layers.Dense(32)(LR4)\n",
    "\n",
    "tc5 = layers.Conv2DTranspose(1, 257, data_format='channels_last')(LR4)\n",
    "\n",
    "LR5=LeakyReLU(alpha=0.1)(tc5)\n",
    "\n",
    "#prediction_layer=layers.Dense(2,activation='softmax')(LR5)\n",
    "\n",
    "prediction_layer = layers.Conv2DTranspose(1,1, activation='softmax')(LR5)\n",
    "\n",
    "model1=Model(input_layer,prediction_layer,name='prediction_model')\n",
    "\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8daaf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=create_batch_data(imgs,masks,imgs.shape[0])\n",
    "\n",
    "##train_label_pos,train_label_neg=train_label[np.where(train_label==0)[0]],train_label[np.where(train_label==1)[0]]\n",
    "\n",
    "train_prediction=model.predict(train_data)\n",
    "\n",
    "val_prediction=model.predict(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090be17b",
   "metadata": {},
   "source": [
    "# One Hot Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d15c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "for i in range(1,2):\n",
    "\n",
    "    imgs = np.load(f'G:/sen11_cross_validation_bitemporal_numpy_image/fold_{i}/train/fold_{i}.npy')\n",
    "\n",
    "    masks = np.load(f'G:/sen11_cross_validation_bitemporal_numpy_mask/fold_{i}/train/fold_{i}.npy')\n",
    "\n",
    "    imgs_valid = np.load(f'G:/sen11_cross_validation_bitemporal_numpy_image/fold_{i}/valid/fold_{i}.npy')\n",
    "\n",
    "    masks_valid = np.load(f'G:/sen11_cross_validation_bitemporal_numpy_mask/fold_{i}/valid/fold_{i}.npy')\n",
    "\n",
    "    masks_one_hot = []\n",
    "\n",
    "    masks_one_hot_valid = []\n",
    "\n",
    "    for m in range(masks.shape[0]):\n",
    "\n",
    "        masks_1d = to_categorical(np.ravel(masks[m]),num_classes=2)\n",
    "\n",
    "        masks_one_hot.append(np.concatenate((np.expand_dims(np.reshape(masks_1d[:,0],(512,512)),axis=2),np.expand_dims(np.reshape(masks_1d[:,1],(512,512)),axis=2)), axis=2))\n",
    "\n",
    "    masks_one_hot = np.stack(masks_one_hot)\n",
    "\n",
    "    for mm in range(masks_valid.shape[0]):\n",
    "\n",
    "        masks_1d_valid = to_categorical(np.ravel(masks_valid[mm]), num_classes=2)\n",
    "\n",
    "        masks_one_hot_valid.append(np.concatenate((np.expand_dims(np.reshape(masks_1d_valid[:,0],(512,512)),axis=2),np.expand_dims(np.reshape(masks_1d_valid[:,1],(512,512)),axis=2)), axis=2))\n",
    "\n",
    "\n",
    "    masks_one_hot_valid = np.stack(masks_one_hot_valid)   \n",
    "\n",
    "    print(masks_one_hot.shape, masks_one_hot_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9620c1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adadelta\n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "#anchor_embedding_train,positive_embedding_train,negative_embedding_train=train_prediction[:,:256],train_prediction[:,256:2*256],train_prediction[:,2*256:3*256]\n",
    "\n",
    "#embedding_t,label_t=shuffle(np.concatenate((positive_embedding_train,negative_embedding_train),axis=0),np.concatenate((train_label_pos,train_label_neg),axis=0),random_state=2)\n",
    "\n",
    "lr_Schedule1=ExponentialDecay(0.001,decay_rate=0.8,decay_steps=1000)\n",
    "\n",
    "es1=EarlyStopping(monitor='val_loss',min_delta=1e-4,patience=100,restore_best_weights=True)\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=lr_Schedule1),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history1=model1.fit(train_prediction,masks_one_hot,batch_size=80, epochs=300,callbacks=[es1],validation_data=(val_prediction,masks_one_hot_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e0a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_change_map(model,model1,imgs_test,embedding_dim=256):\n",
    "\n",
    "    flood_maps=[]\n",
    "\n",
    "    for i in range(imgs_test.shape[0]):\n",
    "        \n",
    "        embedding_input=create_batch_data(np.expand_dims(imgs_test[i],axis=0))\n",
    "            \n",
    "        embedding=model.predict(test_prediction)\n",
    "\n",
    "        flood_maps.append(np.argmax(model1.predict(embedding),axis=2))    \n",
    "            \n",
    "                            \n",
    "    return(flood_map) \n",
    "\n",
    "\n",
    "embedding_dim=256\n",
    "\n",
    "NUM_FOLD =10\n",
    "\n",
    "flood_maps = []\n",
    "\n",
    "for i in range(1,Num_Fold+1):\n",
    "\n",
    "    imgs_test = np.load(f'G:/sen11_cross_validation_bitemporal_numpy_image/fold_{i}/test/fold_{i}.npy')\n",
    "    \n",
    "    masks_test = np.load(f'G:/sen11_cross_validation_bitemporal_numpy_mask/fold_{i}/test/fold_{i}.npy')\n",
    "\n",
    "\n",
    "    flood_maps.append(create_change_map(model,model1,imgs_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
