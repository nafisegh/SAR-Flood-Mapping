{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.optimizers import *\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras.utils.vis_utils import plot_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path\n",
    "\n",
    "#sys.path.append('c:\\programdata\\anaconda3\\envs\\tf2.8\\lib\\site-packages (3.4.1)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def read_as_array(path,file_name):\n",
    "\n",
    "    gdal_file=gdal.Open(path+'/'+file_name)\n",
    "\n",
    "    array=np.zeros((gdal_file.RasterYSize,gdal_file.RasterXSize,gdal_file.RasterCount))\n",
    "    \n",
    "    for i in range(gdal_file.RasterCount):\n",
    "\n",
    "        gdal_file_band=gdal_file.GetRasterBand(i+1)\n",
    "\n",
    "        array[:,:,i]=gdal_file_band.ReadAsArray()\n",
    "        \n",
    "    return(array)     \n",
    "\n",
    "path='D:/Nafiseh/flood_proposal'\n",
    "\n",
    "#preflood_image_name,postflood_image_name='0417_clip_2.tif','20190428_coregis_stack_bands.tif'\n",
    "\n",
    "#preflood_image_name,postflood_image_name='subset_1_of_S1A_IW_GRDH_1SDV_20190408T225218_20190408T225243_Cal_Spk_TC_2.tif','subset_0_of_S1A_IW_GRDH_1SDV_20190425T230019_20190425T230055_Cal_Spk_TC_4_2.tif'\n",
    "#coh_image_name='S1A_IW_SLC__1SDV_20190408T225217_20190502_20190514_20190526_split_Orb_Stack_esd_coh_deb_flt_ML_TC_Stack.tif'\n",
    "\n",
    "\n",
    "#preflood_array=read_as_array(path,preflood_image_name)\n",
    "\n",
    "#postflood_array=read_as_array(path,postflood_image_name)\n",
    "\n",
    "#postflood_array=np.delete(postflood_array,-1,axis=1)\n",
    "\n",
    "#stack_image_name='corgistration_intensity_coh_Stack.tif'\n",
    "\n",
    "#stack_image_name='subset_0_of_S1A_IW_GRDH_1SDV_Cal_Spk_TC_Stack_subset.tif'\n",
    "#stack_image_name_2='subset_1_of_S1A_IW_GRDH_1SDV_20190408T225218_20190507T23009_Cal_Spk_TC_Stack_2_subset.tif'\n",
    "\n",
    "#train_name='collocate_int_coh_leverkhuzen_2.tif'\n",
    "\n",
    "train_name='stack_train_RCM_3_20211118_1130.tif'\n",
    "\n",
    "#test_name='collocate_S1B_int_coh.tif'\n",
    "test_name='stack_test_RCM_2_3_2021119_1130.tif'\n",
    "\n",
    "\n",
    "#GRT_Mask_name='flood_mask_mosaic_to_new_raster.tif'\n",
    "\n",
    "#MNDWI_Mask_name='S2_MNDWI_flood_mask_clip3_binary_region_group_nibble_mask_nibble_boundary_clean.tif'\n",
    "\n",
    "#stack_array=read_as_array(path,stack_image_name)\n",
    "#stack_array_2=read_as_array(path,stack_image_name_2)\n",
    "#label=read_as_array(path,MNDWI_Mask_name)\n",
    "#label_test=read_as_array(path,GRT_Mask_name)\n",
    "#label[label>=1]=1\n",
    "\n",
    "train_array_int=read_as_array(path,train_name)\n",
    "##temp=train_array_int\n",
    "#temp[temp==0]=10**-10\n",
    "#stack_train_int=np.log10(temp) #vv channel for S1 #HH and HV channels for RCM\n",
    "stack_train_int=train_array_int\n",
    "\n",
    "test_array_int=read_as_array(path,test_name)\n",
    "temp_=test_array_int\n",
    "##temp_=np.copy(test_array)\n",
    "#temp_[temp_==0]=10**-10\n",
    "#stack_test_int=np.log10(temp_) #vv channel for S1 #HH and HV channels for RCM\n",
    "stack_test_int=test_array_int\n",
    "\n",
    "#GRD_SLC_stack_train_s=stack_train_int[:,:,[0,1,2,3,5,6,8,9]]\n",
    "GRD_SLC_stack_train_s=stack_train_int\n",
    "\n",
    "#GRD_SLC_stack_test_s=stack_test_int[:,:,[0,1,2,3,5,6,8,9]]\n",
    "GRD_SLC_stack_test_s=stack_test_int\n",
    "\n",
    "#preflood_array_=np.concatenate((np.delete(np.repeat(stack_array[:2000,500:2000,2:4],2,axis=2),-1,axis=2),coh_co_vv_array_),axis=2) #VH;VV;VH db\n",
    "#postflood_array_=np.concatenate((np.delete(np.repeat(stack_array[:2000,500:2000,14:16],2,axis=2),-1,axis=2),coh_post_vv_array_),axis=2)\n",
    "#preflood_array_=np.concatenate((stack_array[:,:,2:4],coh_co_vv_array_),axis=2)\n",
    "#postflood_array_=np.concatenate((stack_array[:,:,-3:-1],coh_post_vv_array_),axis=2)\n",
    "\n",
    "#intensity_array_vv=stack_array[500:2000,500:2000,[7,3]]\n",
    "\n",
    "#coh_array_vv=np.expand_dims(stack_array[:,:,[8,10]],axis=2)  #coherency_co and coherency_post; vv; post flood coherency was considered as reference\n",
    "\n",
    "#coherency_array_vv=np.expand_dims((intensity_array_vv,coh_vv_array_))\n",
    "#postflood_array_=np.expand_dims(stack_array_2[500:2000,500:2000,7],axis=2)\n",
    "#label=stack_array[780:1080,0:300,-1] #flood mask for 25th April\n",
    "\n",
    "\n",
    "\n",
    "#label_test=np.round(stack_array_2[500:2000,500:2000,-1])\n",
    "#label_test=np.round(stack_array_2[780:1080,0:300,-1])\n",
    "#label_test[np.isnan(label_test)]=0\n",
    "#label_test[np.where(label_test==0)[0]]=0\n",
    "#label_test[np.where(label_test>1)[0]]=1 #making label binary (the original labels were not binary maybe because of the co-registration); flood mask for 5th May\n",
    "\n",
    "#print(GRD_SLC_stack_train_s.shape,np.unique(label),np.unique(label_test))\n",
    "print(GRD_SLC_stack_train_s.shape,GRD_SLC_stack_test_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with Simple Log-Ratio method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.ndimage import zoom\n",
    "import skimage\n",
    "\n",
    "\n",
    "fig,ax=plt.subplots(2,1,figsize=(10,5))\n",
    "\n",
    "axes=np.ravel(ax)\n",
    "\n",
    "gt=read_as_array('D:/Nafiseh/flood_proposal/','hydrography_area_mask_leverkhuzen_clip.tif')\n",
    "\n",
    "log_ratio=np.log10(test_array_int[:,:,3]/test_array_int[:,:,1]) #log10(co/pre)\n",
    "\n",
    "log_ratio[~np.isfinite(log_ratio)]=0\n",
    "\n",
    "otsu_threshold=skimage.filters.threshold_otsu(log_ratio)\n",
    "\n",
    "log_ratio[log_ratio>otsu_threshold]=1\n",
    "\n",
    "log_ratio[log_ratio<=otsu_threshold]=0\n",
    "\n",
    "log_ratio_r=zoom(log_ratio,[gt.shape[0]/log_ratio.shape[0],gt.shape[1]/log_ratio.shape[1]],order=0)\n",
    "\n",
    "im=axes[0].imshow(log_ratio_r)\n",
    "\n",
    "axes[0].axis('off')\n",
    "\n",
    "im=axes[1].imshow(gt)\n",
    "\n",
    "axes[1].axis('off')\n",
    "\n",
    "cax_colorbar=fig.add_axes([0.65, 0.15, 0.05, 0.7])\n",
    "\n",
    "cb=fig.colorbar(im,ticks=[0,1],cax=cax_colorbar)\n",
    "\n",
    "cb.set_ticklabels(['background','flood/water bodies'],fontsize='x-large')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_log_ratio=confusion_matrix(np.ravel(gt),np.ravel(log_ratio_r))\n",
    "print(classification_report(np.ravel(gt),np.ravel(log_ratio_r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import skimage\n",
    "\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getThreshold(data):\n",
    "    \n",
    "    n = data.shape[2]\n",
    "    \n",
    "    threshold = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        band_data = data[:,:,i]\n",
    "\n",
    "        # calculate threshold using Otsu method\n",
    "        threshold_otsu = skimage.filters.threshold_otsu(band_data)\n",
    "        # calculate threshold using minimum method\n",
    "        threshold_minimum = skimage.filters.threshold_minimum(band_data)\n",
    "        # get number of pixels for both thresholds\n",
    "        numPixOtsu = len(band_data[abs(band_data - threshold_otsu) < 0.1])\n",
    "        numPixMinimum = len(band_data[abs(band_data - threshold_minimum) < 0.1])\n",
    "\n",
    "        # if number of pixels at minimum threshold is less than 1% of number of pixels at Otsu threshold\n",
    "        if abs(numPixMinimum/(numPixOtsu+1)) < 0.01:\n",
    "            # adjust band data according\n",
    "            if threshold_otsu < threshold_minimum:\n",
    "                \n",
    "                band_data = band_data[band_data < threshold_minimum]\n",
    "                \n",
    "                if np.any(band_data!=np.mean(np.ravel(band_data))):\n",
    "                    \n",
    "                    threshold_minimum = skimage.filters.threshold_minimum(band_data)\n",
    "            else:\n",
    "                \n",
    "                band_data = band_data[band_data > threshold_minimum]\n",
    "                threshold_minimum = skimage.filters.threshold_minimum(band_data)\n",
    "\n",
    "            numPixMinimum = len(band_data[abs(band_data - threshold_minimum) < 0.1])\n",
    "\n",
    "        # select final threshold\n",
    "        if abs(numPixMinimum/(numPixOtsu+1)) < 0.01:\n",
    "            threshold.append(threshold_otsu)\n",
    "        else:\n",
    "            threshold.append(threshold_minimum)\n",
    "\n",
    "    return threshold\n",
    "\n",
    "dem_name='Abbotsford_dem_2012.tif'\n",
    "#dem_name='dem_gatineau.tif'\n",
    "#dem_name='dem_leverkhuzen_SRTMGL1.tif'\n",
    "\n",
    "dem=read_as_array(path,dem_name)\n",
    "\n",
    "dem_row,dem_col=dem.shape[0],dem.shape[1]\n",
    "\n",
    "#stack_train_int_coh=GRD_SLC_stack_train_s[:,:,[3,7]]\n",
    "stack_train_int_coh=GRD_SLC_stack_train_s #HH and HV bands\n",
    "\n",
    "#stack_test_int_coh=GRD_SLC_stack_test_s[:,:,[3,7]]\n",
    "stack_test_int_coh=GRD_SLC_stack_test_s #HH and HV bands\n",
    "\n",
    "\n",
    "row=stack_train_int_coh.shape[0]\n",
    "col=stack_train_int_coh.shape[1]\n",
    "\n",
    "row1=stack_test_int_coh.shape[0]\n",
    "col1=stack_test_int_coh.shape[1]\n",
    "\n",
    "\n",
    "dem_r=zoom(dem,(row/dem_row,col/dem_col,1),order=0)\n",
    "\n",
    "dem_r_test=zoom(dem,(row1/dem_row,col1/dem_col,1),order=0)\n",
    "\n",
    "dem_threshold=getThreshold(dem_r)\n",
    "\n",
    "int_thresholds=getThreshold(np.divide(stack_train_int_coh,256))\n",
    "\n",
    "int_thresholds_test=getThreshold(np.divide(stack_test_int_coh,256))\n",
    "\n",
    "#mask_vv_pre=np.zeros((row,col))\n",
    "mask_vv_co=np.zeros((row,col))\n",
    "mask_vv_coh_co=np.zeros((row,col))\n",
    "mask_intersection=np.zeros((row,col))\n",
    "mask_union=np.zeros((row,col))\n",
    "mask_union_test=np.zeros((row1,col1))\n",
    "mask_intersection_test=np.zeros((row1,col1))\n",
    "mask_vv_co_test=np.zeros((row1,col1))\n",
    "mask_vv_coh_co_test=np.zeros((row1,col1))\n",
    "\n",
    "##mask_vv_pre[stack_train_int[:,:,0]<int_thresholds[0]]=1\n",
    "\n",
    "mask_vv_co[stack_train_int_coh[:,:,0]<int_thresholds[0]]=1 #co_event vv:sentinel-1; hh:RCM\n",
    "\n",
    "mask_vv_coh_co[stack_train_int_coh[:,:,1]<int_thresholds[1]]=1 #co_event coh:sentinel-1; hv (intensity):RCM\n",
    "\n",
    "mask_intersection[(mask_vv_co==1) & (mask_vv_coh_co==1) & (np.squeeze(dem_r,axis=2)<dem_threshold[0])]=1\n",
    "\n",
    "mask_union[((mask_vv_co==1) | (mask_vv_coh_co==1)) & (np.squeeze(dem_r,axis=2)<dem_threshold[0])]=1\n",
    "\n",
    "mask_vv_co_test[stack_test_int_coh[:,:,0]<int_thresholds_test[0]]=1 #co_event\n",
    "\n",
    "mask_vv_coh_co_test[stack_test_int_coh[:,:,1]<int_thresholds_test[1]]=1\n",
    "\n",
    "mask_union_test[((mask_vv_co_test==1) | (mask_vv_coh_co_test==1)) & (np.squeeze(dem_r_test,axis=2)<dem_threshold[0])]=1\n",
    "\n",
    "mask_intersection_test[(mask_vv_co_test==1) & (mask_vv_coh_co_test==1) & (np.squeeze(dem_r_test,axis=2)<dem_threshold[0])]=1\n",
    "\n",
    "fig,ax=plt.subplots(2,3,figsize=(10,5))\n",
    "\n",
    "ax[0,0].imshow(mask_vv_co)\n",
    "\n",
    "ax[0,0].axis('off')\n",
    "\n",
    "#ax[0,0].set_title('VV mask co event (2021/07/16)')\n",
    "ax[0,0].set_title('HH mask co event (2021/11/18)')\n",
    "\n",
    "ax[0,1].imshow(mask_vv_coh_co)\n",
    "\n",
    "ax[0,1].axis('off')\n",
    "\n",
    "#ax[0,1].set_title('Co event coherency VV mask \\n (2021/06/24-2021/07/06)')\n",
    "\n",
    "ax[0,1].set_title('HV mask co event \\n (2021/11/18)')\n",
    "\n",
    "ax[0,2].imshow(mask_union)\n",
    "\n",
    "ax[0,2].axis('off')\n",
    "\n",
    "ax[0,2].set_title('Union Mask')\n",
    "\n",
    "ax[1,0].imshow(mask_vv_co_test)\n",
    "\n",
    "ax[1,0].axis('off')\n",
    "\n",
    "#ax[1,0].set_title('VV mask co event (2021/07/18)')\n",
    "\n",
    "ax[1,0].set_title('HH mask co event (2021/11/19)')\n",
    "\n",
    "ax[1,1].imshow(mask_vv_coh_co_test)\n",
    "\n",
    "#ax[1,1].set_title('Co event coherency VV mask \\n (2021/07/07-2021/07/19)')\n",
    "\n",
    "ax[1,1].set_title('HV mask co event \\n (2021/11/19)')\n",
    "\n",
    "ax[1,1].axis('off')\n",
    "\n",
    "ax[1,2].imshow(mask_union_test)\n",
    "\n",
    "ax[1,2].set_title('Union Mask')\n",
    "\n",
    "ax[1,2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax=plt.subplots(1,3,figsize=(10,5))\n",
    "\n",
    "ax[0].imshow(mask_intersection,cmap='magma') #25th April flood mask\n",
    "\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(mask_intersection_test,cmap='magma') #7th May flood mask\n",
    "\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(mask_intersection_test,cmap='magma')\n",
    "\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def vectorize_3d_array(three_d_array):\n",
    "    \n",
    "    array=np.zeros((three_d_array.shape[0]*three_d_array.shape[1],three_d_array.shape[2]))\n",
    "    \n",
    "    for i in range(three_d_array.shape[2]):\n",
    "    \n",
    "        array[:,i]=np.ravel(three_d_array[:,:,i])\n",
    "        \n",
    "    return(array)     \n",
    "\n",
    "\n",
    "preflood_1d_array=vectorize_3d_array(preflood_array_)\n",
    "\n",
    "#postflood_1d_array=vectorize_3d_array(postflood_array_)\n",
    "\n",
    "NDWI_pre=np.nan_to_num(np.log(np.divide((preflood_1d_array[:,0]-preflood_1d_array[:,1]),(preflood_1d_array[:,0]+preflood_1d_array[:,1]))))\n",
    "\n",
    "#NDWI_post=np.nan_to_num(np.divide((postflood_1d_array[:,1]-postflood_1d_array[:,3]),(postflood_1d_array[:,1]+postflood_1d_array[:,3])))\n",
    "\n",
    "pre_kmeans=KMeans(n_clusters=3,random_state=0).fit(NDWI_pre.reshape(-1,1))\n",
    "\n",
    "preflood_cluster=pre_kmeans.predict(NDWI_pre.reshape(-1,1))\n",
    "\n",
    "#post_kmeans=KMeans(n_clusters=3,random_state=0).fit(NDWI_post.reshape(-1,1))\n",
    "\n",
    "#postflood_cluster=post_kmeans.predict(NDWI_post.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Clustering Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "path='D:/flood_proposal'\n",
    "#np.save(path+'/postflood_cluster.npy',postflood_cluster)\n",
    "#np.save(path+'/preflood_cluster.npy',preflood_cluster)\n",
    "#postflood_cluster=np.load(path+'/postflood_cluster.npy')\n",
    "preflood_cluster=np.load(path+'/preflood_cluster.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Clustering Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.imshow(np.reshape(postflood_array_,(postflood_array_.shape[0],postflood_array_.shape[1])),cmap='magma')\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_preflood_clustering=np.reshape(preflood_cluster,(preflood_array_.shape[0],preflood_array_.shape[1]))\n",
    "kmeans_postflood_clustering=np.reshape(postflood_cluster,(preflood_array_.shape[0],preflood_array_.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data Preparation (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "\n",
    "def prepare_train_data(flood_array,label):\n",
    "\n",
    "    row,col=flood_array.shape[0],flood_array.shape[1]\n",
    "    \n",
    "    neigh_size=256\n",
    "\n",
    "    half_size=np.int((neigh_size-1)/2)\n",
    "\n",
    "    train_sample=[]\n",
    "\n",
    "    label_new=[]\n",
    "\n",
    "    for i in range(half_size,row-half_size+1,neigh_size):\n",
    "\n",
    "        for j in range(half_size,col-half_size+1,neigh_size):\n",
    "\n",
    "            train_sample.append(flood_array[i-half_size:i+half_size+1,j-half_size:j+half_size+1,:])\n",
    "\n",
    "            label_new.append(label[i-half_size:i+half_size+1,j-half_size:j+half_size+1])\n",
    "\n",
    "            #central_pixel.append((i,j))\n",
    "\n",
    "    return(train_sample,label_new)\n",
    "\n",
    "def prepare_test_data(postflood_array,label_test):\n",
    "    \n",
    "    neigh_size=256\n",
    "    \n",
    "    half_size=np.int((neigh_size-1)/2)\n",
    "    \n",
    "    test_sample=[]\n",
    "    \n",
    "    label_new=[]\n",
    "    \n",
    "    #postflood_array_pad=np.pad(postflood_array,((half_size,half_size),(half_size,half_size),(0,0)),'symmetric')\n",
    "    \n",
    "    #label_test_pad=np.pad(label_test,((half_size,half_size),(half_size,half_size),(0,0)),'symmetric')\n",
    "    \n",
    "    row,col=postflood_array.shape[0],postflood_array.shape[1]\n",
    "    \n",
    "    for i in range(half_size,row-half_size+1,neigh_size):\n",
    "        \n",
    "        for j in range(half_size,col-half_size+1,neigh_size):\n",
    "            \n",
    "            test_sample.append(postflood_array[i-half_size:i+half_size+1,j-half_size:j+half_size+1,:])\n",
    "            \n",
    "            label_new.append(label_test[i-half_size:i+half_size+1,j-half_size:j+half_size+1])\n",
    "\n",
    "            \n",
    "    return(test_sample,label_new)       \n",
    "\n",
    "#train_sample,label=prepare_train_data(intensity_array_vv,label)            \n",
    "#test_sample,label_test=prepare_test_data(postflood_array_,label_test)\n",
    "\n",
    "\n",
    "##label=zoom(label,(300/label.shape[0],300/label.shape[1],1),order=0)\n",
    "#mask_union=np.expand_dims(mask_union,axis=2)\n",
    "train_sample,label=prepare_train_data(GRD_SLC_stack_train_s,mask_union)\n",
    "#mask_union_test=np.expand_dims(mask_union_test,axis=2)\n",
    "##label_test=zoom(label_test,(300/label_test.shape[0],300/label_test.shape[1],1),order=0)\n",
    "test_sample,label_test=prepare_test_data(GRD_SLC_stack_test_s,mask_union_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data Preparation (Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import zoom\n",
    "\n",
    "import random\n",
    "\n",
    "def resample_data(data_sample,label,mode):\n",
    "\n",
    "    data_resampled=[]\n",
    "    \n",
    "    label_new=[]\n",
    "    \n",
    "    patch_size=256\n",
    "    \n",
    "    #if label.ndim==2:\n",
    "       \n",
    "       #label=np.ravel(label) \n",
    "\n",
    "    for k in range(len(data_sample)):\n",
    "        \n",
    "        #print(data_sample[k].shape)\n",
    "        \n",
    "        if data_sample[k].shape<(patch_size,patch_size):\n",
    "\n",
    "            data_resampled.append(zoom(data_sample[k],zoom=[patch_size/data_sample[k].shape[0],patch_size/data_sample[k].shape[1],1],order=3))\n",
    "\n",
    "            label_new.append(zoom(label[k],zoom=[patch_size/label[k].shape[0],patch_size/label[k].shape[1]],order=1))\n",
    "            \n",
    "            #continue\n",
    "        \n",
    "        elif data_sample[k].shape==(patch_size,patch_size):\n",
    "            \n",
    "            data_resampled.append(data_sample[k])\n",
    "            \n",
    "            label_new.append(label[k])\n",
    "            \n",
    "        elif data_sample[k].shape>(patch_size,patch_size):\n",
    "            \n",
    "            for i in range(round(data_sample[k].shape[0]/patch_size)):\n",
    "                \n",
    "                for j in range(round(data_sample[k].shape[1]/patch_size)):\n",
    "\n",
    "                \n",
    "                    temp=data_sample[k][i*patch_size:(i+1)*patch_size,j*patch_size:(j+1)*patch_size]\n",
    "                \n",
    "                                \n",
    "                    if temp.shape<(patch_size,patch_size):\n",
    "\n",
    "                    \n",
    "                        data_resampled.append(zoom(temp,zoom=[patch_size/temp.shape[0],patch_size/temp.shape[1],1],order=3))\n",
    "                        #continue\n",
    "                        label_new.append(zoom(label[k],zoom=[patch_size/label[k].shape[0],patch_size/label[k].shape[1]],order=1)) \n",
    "\n",
    "                    else:\n",
    "                    \n",
    "                        data_resampled.append(temp) \n",
    "                    \n",
    "                        label_new.append(zoom(label[k],zoom=[patch_size/label[k].shape[0],patch_size/label[k].shape[1]],order=1))    \n",
    "                \n",
    "                   \n",
    "\n",
    "    data_resampled=np.stack(data_resampled) \n",
    "\n",
    "    label_new=np.stack(label_new)\n",
    "\n",
    "    print(f' {mode} Data Shape: {data_resampled.shape}, {mode} Label Shape: {label_new.shape}')\n",
    "    \n",
    "    return (data_resampled,label_new)\n",
    "\n",
    "train_resampled,label_new=resample_data(train_sample,label,'Train')   \n",
    "\n",
    "test_resampled,label_test_new=resample_data(test_sample,label_test,'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def data_augmentation(data,label_new,image_count=150):\n",
    "\n",
    "        augmented_images=[]\n",
    "        \n",
    "        label_aug=[]\n",
    "\n",
    "        datagen_hflip=ImageDataGenerator(rotation_range=0.1, horizontal_flip=True)\n",
    "        \n",
    "        for sn in range(data.shape[0]):\n",
    "\n",
    "            it=datagen_hflip.flow(np.expand_dims(data[sn,:,:,:],axis=0),batch_size=1)\n",
    "\n",
    "            for j in range(image_count):\n",
    "    \n",
    "                augmented_images.append(np.squeeze(it.next(),axis=0))\n",
    "        \n",
    "                label_aug.append(label_new[sn,:,:])\n",
    "        \n",
    "        return(np.stack(augmented_images),np.stack(label_aug)) \n",
    "    \n",
    "#positive_idx,negative_idx=np.where(np.array(label_new)==0),np.where(np.array(label_new)==1)\n",
    "\n",
    "#train_resampled_aug_pos,label_aug_pos=data_augmentation(train_resampled,label_new,positive_idx,20) #positive is background\n",
    "\n",
    "train_resampled_aug,label_aug=data_augmentation(train_resampled,label_new)\n",
    "\n",
    "train_resampled_aug=np.concatenate((train_resampled,train_resampled_aug),axis=0)\n",
    "\n",
    "label_aug=np.concatenate((label_new,label_aug),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data_resampled,mode):\n",
    "    \n",
    "    for i in range(data_resampled.shape[0]):\n",
    "\n",
    "            if len(data_resampled.shape)==4:\n",
    "                \n",
    "                for j in range(data_resampled.shape[3]):\n",
    "\n",
    "                    a=data_resampled[i,:,:,j]\n",
    "\n",
    "                    min_,max_=np.min(np.ravel(data_resampled[i,:,:,j])),np.max(np.ravel(data_resampled[i,:,:,j]))\n",
    "\n",
    "                    data_resampled[i,:,:,j]=(a-min_)/(max_-min_)\n",
    "                \n",
    "            elif len(data_resampled.shape)==2: \n",
    "                \n",
    "                a=data_resampled[i,:]\n",
    "\n",
    "                min_,max_=np.min(np.ravel(data_resampled[i,:])),np.max(np.ravel(data_resampled[i,:]))\n",
    "\n",
    "                data_resampled[i,:]=(a-min_)/(max_-min_)\n",
    "\n",
    "    print(f' {mode} Data Shape: {data_resampled.shape}') \n",
    "    \n",
    "    return(data_resampled)\n",
    "\n",
    "train_resampled_aug=normalize_data(train_resampled_aug,'Train')\n",
    "\n",
    "test_resampled=normalize_data(test_resampled, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_resampled,label_new=train_resampled_aug,label_aug\n",
    "\n",
    "#positive here is the background\n",
    "\n",
    "train_resampled_,val_resampled,train_label,val_label=train_test_split(train_resampled,label_new,test_size=0.2,random_state=1)\n",
    "\n",
    "print(f' Train Data Shape: {train_resampled_.shape}, Validation Data Shape: {val_resampled.shape}')\n",
    "\n",
    "print(f' \\n Train Label Shape: {train_label.shape}, Validation Label Shape: {val_label.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,axes=plt.subplots(2,2,figsize=(10,5))\n",
    "\n",
    "for i,ax in zip(range(4),axes.ravel()):\n",
    "    \n",
    "    ax.imshow(train_resampled[i,:,:,1])\n",
    "    \n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ Siamese Segmentation models ]\n",
    "#\n",
    "# Altered code from:\n",
    "# https://github.com/qubvel/segmentation_models\n",
    "# more specifically combined from files:\n",
    "# - https://github.com/qubvel/segmentation_models/blob/master/segmentation_models/unet/builder.py\n",
    "# - https://github.com/qubvel/segmentation_models/blob/master/segmentation_models/unet/blocks.py\n",
    "# under commit https://github.com/qubvel/segmentation_models/commit/9c68d81d66e4fb856770a87b450a43bb2ae6ddba\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Activation\n",
    "from keras.models import Model\n",
    "\n",
    "from segmentation_models.utils import freeze_model\n",
    "from segmentation_models.utils import legacy_support\n",
    "from segmentation_models.backbones import get_backbone, get_feature_layers\n",
    "\n",
    "from segmentation_models.unet.blocks import Transpose2D_block\n",
    "from segmentation_models.utils import get_layer_number, to_tuple\n",
    "\n",
    "from keras.layers import Concatenate\n",
    "from segmentation_models.unet.blocks import UpSampling2D, handle_block_names, ConvRelu\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input\n",
    "from keras.models import load_model\n",
    "\n",
    "old_args_map = {\n",
    "    'freeze_encoder': 'encoder_freeze',\n",
    "    'skip_connections': 'encoder_features',\n",
    "    'upsample_rates': None,  # removed\n",
    "    'input_tensor': None,  # removed\n",
    "}\n",
    "\n",
    "\n",
    "#@legacy_support(old_args_map)\n",
    "def SiameseUnet(backbone_name='vgg16',\n",
    "         input_shape=(None, None, 3),\n",
    "         classes=1,\n",
    "         activation='sigmoid',\n",
    "         encoder_weights='imagenet',\n",
    "         encoder_freeze=False,\n",
    "         encoder_features='default',\n",
    "         decoder_block_type='upsampling',\n",
    "         decoder_filters=(256, 128, 64, 32, 16),\n",
    "         decoder_use_batchnorm=True,\n",
    "         **kwargs):\n",
    "    \"\"\" Unet_ is a fully convolution neural network for image semantic segmentation\n",
    "        Args:\n",
    "            backbone_name: name of classification model (without last dense layers) used as feature\n",
    "                extractor to build segmentation model.\n",
    "            input_shape: shape of input data/image ``(H, W, C)``, in general\n",
    "                case you do not need to set ``H`` and ``W`` shapes, just pass ``(None, None, C)`` to make your model be\n",
    "                able to process images af any size, but ``H`` and ``W`` of input images should be divisible by factor ``32``.\n",
    "            classes: a number of classes for output (output shape - ``(h, w, classes)``).\n",
    "            activation: name of one of ``keras.activations`` for last model layer\n",
    "                (e.g. ``sigmoid``, ``softmax``, ``linear``).\n",
    "            encoder_weights: one of ``None`` (random initialization), ``imagenet`` (pre-training on ImageNet).\n",
    "            encoder_freeze: if ``True`` set all layers of encoder (backbone model) as non-trainable.\n",
    "            encoder_features: a list of layer numbers or names starting from top of the model.\n",
    "                Each of these layers will be concatenated with corresponding decoder block. If ``default`` is used\n",
    "                layer names are taken from ``DEFAULT_SKIP_CONNECTIONS``.\n",
    "            decoder_block_type: one of blocks with following layers structure:\n",
    "                - `upsampling`:  ``Upsampling2D`` -> ``Conv2D`` -> ``Conv2D``\n",
    "                - `transpose`:   ``Transpose2D`` -> ``Conv2D``\n",
    "            decoder_filters: list of numbers of ``Conv2D`` layer filters in decoder blocks\n",
    "            decoder_use_batchnorm: if ``True``, ``BatchNormalisation`` layer between ``Conv2D`` and ``Activation`` layers\n",
    "                is used.\n",
    "        Returns:\n",
    "            ``keras.models.Model``: **Unet**\n",
    "        .. _Unet:\n",
    "            https://arxiv.org/pdf/1505.04597\n",
    "    \"\"\"\n",
    "\n",
    "    load_weights_from = None\n",
    "    if encoder_weights is not \"imagenet\" and encoder_weights is not None:\n",
    "        load_weights_from = encoder_weights\n",
    "        encoder_weights = None\n",
    "\n",
    "\n",
    "    backbone = get_backbone(backbone_name,\n",
    "                            input_shape=input_shape,\n",
    "                            input_tensor=None,\n",
    "                            weights=encoder_weights,\n",
    "                            include_top=False)\n",
    "\n",
    "    if load_weights_from is not None:\n",
    "        model_to_load_weights_from = load_model(load_weights_from)\n",
    "\n",
    "        # now let's assume that this loaded model had its own \"top\" upsampling section trained on another task\n",
    "        # let's transplant what we can, that is the backbone encoder\n",
    "\n",
    "        output = model_to_load_weights_from.layers[len(backbone.layers)-1].output  # remove activation and last conv layer\n",
    "        transplant = keras.models.Model(model_to_load_weights_from.input, output)\n",
    "        #transplant.summary()\n",
    "\n",
    "        transplant.save(\"transplant.h5\") # hacky way\n",
    "        backbone.load_weights(\"transplant.h5\")\n",
    "\n",
    "        # Check if the weights have been loaded\n",
    "        \"\"\"\n",
    "        inspect_i = 0\n",
    "        import numpy as np\n",
    "        w1 = np.asarray(transplant.get_weights()[inspect_i])\n",
    "        print(w1)\n",
    "        w2 = np.asarray(backbone.get_weights()[inspect_i])\n",
    "        print(w2)\n",
    "        \"\"\"\n",
    "        print(\"Loaded weights into \",backbone_name,\"from\",load_weights_from)\n",
    "\n",
    "    if encoder_features == 'default':\n",
    "        encoder_features = get_feature_layers(backbone_name, n=4)\n",
    "\n",
    "    model = build_siamese_unet(backbone,\n",
    "                       classes,\n",
    "                       encoder_features,\n",
    "                       decoder_filters=decoder_filters,\n",
    "                       block_type=decoder_block_type,\n",
    "                       activation=activation,\n",
    "                       n_upsample_blocks=len(decoder_filters),\n",
    "                       upsample_rates=(2, 2, 2, 2, 2),\n",
    "                       use_batchnorm=decoder_use_batchnorm,\n",
    "                       input_shape=input_shape)\n",
    "\n",
    "    # lock encoder weights for fine-tuning\n",
    "    if encoder_freeze:\n",
    "        freeze_model(backbone)\n",
    "\n",
    "    model.name = 'u-{}'.format(backbone_name)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def Siamese_Upsample2D_block(filters, stage, kernel_size=(3,3), upsample_rate=(2,2),\n",
    "                     use_batchnorm=False, skip_a=None, skip_b=None):\n",
    "\n",
    "    def layer(input_tensor):\n",
    "\n",
    "        conv_name, bn_name, relu_name, up_name = handle_block_names(stage)\n",
    "\n",
    "        x = UpSampling2D(size=upsample_rate, name=up_name)(input_tensor)\n",
    "\n",
    "        if skip_a is not None and skip_b is not None:\n",
    "            x = Concatenate()([x, skip_a, skip_b]) # siamese concatenation\n",
    "\n",
    "        x = ConvRelu(filters, kernel_size, use_batchnorm=use_batchnorm,\n",
    "                     conv_name=conv_name + '1', bn_name=bn_name + '1', relu_name=relu_name + '1')(x)\n",
    "\n",
    "        x = ConvRelu(filters, kernel_size, use_batchnorm=use_batchnorm,\n",
    "                     conv_name=conv_name + '2', bn_name=bn_name + '2', relu_name=relu_name + '2')(x)\n",
    "\n",
    "        return x\n",
    "    return layer\n",
    "\n",
    "\n",
    "def build_siamese_unet(backbone, classes, skip_connection_layers,\n",
    "               decoder_filters=(256,128,64,32,16),\n",
    "               upsample_rates=(2,2,2,2,2),\n",
    "               n_upsample_blocks=5,\n",
    "               block_type='upsampling',\n",
    "               activation='sigmoid',\n",
    "               use_batchnorm=True,\n",
    "               input_shape=(None, None, 3)):\n",
    "\n",
    "    verbose = False\n",
    "    if verbose:\n",
    "        print(\"Entered build_unet with arguments:\")\n",
    "        print(\"backbone\",backbone)\n",
    "        #print(\"---\\n\")\n",
    "        #backbone.summary()\n",
    "        #print(\"---\\n\")\n",
    "\n",
    "\n",
    "        print(\"classes\",classes)\n",
    "        print(\"skip_connection_layers\",skip_connection_layers)\n",
    "        print(\"decoder_filters\",decoder_filters)\n",
    "        print(\"upsample_rates\",upsample_rates)\n",
    "        print(\"n_upsample_blocks\",n_upsample_blocks)\n",
    "        print(\"block_type\",block_type)\n",
    "        print(\"activation\",activation)\n",
    "        print(\"use_batchnorm\",use_batchnorm)\n",
    "\n",
    "    input = backbone.input\n",
    "    x = backbone.output\n",
    "\n",
    "    # Prepare for multiple heads in siamese nn:\n",
    "\n",
    "    skip_connection_idx = ([get_layer_number(backbone, l) if isinstance(l, str) else l\n",
    "                               for l in skip_connection_layers])\n",
    "    if verbose:\n",
    "        print(\"skip_connection_idx\", skip_connection_idx)\n",
    "\n",
    "    skip_connections = []\n",
    "    for idx in skip_connection_idx:\n",
    "        skip_connection = backbone.layers[idx].output\n",
    "        skip_connections.append(skip_connection)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"skip_connections layers\", len(skip_connections), skip_connections)\n",
    "    #4 layers\n",
    "    # 'stage4_unit1_relu1/Relu:0' shape=(?, 16, 16, 256)\n",
    "    # 'stage3_unit1_relu1/Relu:0' shape=(?, 32, 32, 128)\n",
    "    # 'stage2_unit1_relu1/Relu:0' shape=(?, 64, 64, 64)\n",
    "    # 'relu0/Relu:0'              shape=(?, 128, 128, 64)\n",
    "\n",
    "    siamese_backbone_model_encode = Model(inputs=[input], outputs=[x]+skip_connections)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"siamese_model_encode.input\", siamese_backbone_model_encode.input)\n",
    "        print(\"siamese_model_encode.output\", siamese_backbone_model_encode.output) # x and the (now 4) skip connections\n",
    "\n",
    "    # Then merging\n",
    "    input_a = Input(shape=(input_shape[0], input_shape[1], input_shape[2]))\n",
    "    input_b = Input(shape=(input_shape[0], input_shape[1], input_shape[2]))\n",
    "\n",
    "    branch_a_outputs = siamese_backbone_model_encode([input_a])\n",
    "    branch_b_outputs = siamese_backbone_model_encode([input_b])\n",
    "\n",
    "    branch_a = branch_a_outputs[0]\n",
    "    branch_b = branch_b_outputs[0]\n",
    "\n",
    "    x = Concatenate(name=\"concatHighLvlFeat\")([branch_a, branch_b]) # both inputs, in theory 8x8x512 + 8x8x512 -> 8x8x1024\n",
    "\n",
    "    skip_connection_outputs_a = branch_a_outputs[1:]\n",
    "    skip_connection_outputs_b = branch_b_outputs[1:]\n",
    "\n",
    "    if block_type == 'transpose':\n",
    "        up_block = Transpose2D_block\n",
    "        assert False # NOT IMPLEMENTED\n",
    "    else:\n",
    "        up_block = Siamese_Upsample2D_block\n",
    "\n",
    "    for i in range(n_upsample_blocks):\n",
    "        skip_connection_a = None\n",
    "        skip_connection_b = None\n",
    "        if i < len(skip_connection_idx): # also till len(skip_connection_outputs_a)\n",
    "            skip_connection_a = skip_connection_outputs_a[i]\n",
    "            skip_connection_b = skip_connection_outputs_b[i]\n",
    "\n",
    "        upsample_rate = to_tuple(upsample_rates[i])\n",
    "\n",
    "        x = up_block(decoder_filters[i], i, upsample_rate=upsample_rate,\n",
    "                     skip_a=skip_connection_a, skip_b=skip_connection_b, use_batchnorm=use_batchnorm)(x)\n",
    "\n",
    "    x = Conv2D(classes, (3,3), padding='same', name='final_conv')(x)\n",
    "    x = Activation(activation, name=activation)(x)\n",
    "\n",
    "    #model = Model(input, x)\n",
    "    full_model = Model(inputs=[input_a, input_b], outputs=x)\n",
    "\n",
    "    return full_model\n",
    "\n",
    "\n",
    "\n",
    "# There is support for all of these (with weights from ImageNet included) ... qubvel/segmentation_models is awesome!\n",
    "# VGG           'vgg16' 'vgg19'\n",
    "# ResNet\t    'resnet18' 'resnet34' 'resnet50' 'resnet101' 'resnet152'\n",
    "# SE-ResNet\t    'seresnet18' 'seresnet34' 'seresnet50' 'seresnet101' 'seresnet152'\n",
    "# ResNeXt\t    'resnext50' 'resnet101'\n",
    "# SE-ResNeXt\t'seresnext50' 'seresnet101'\n",
    "# SENet154\t    'senet154'\n",
    "# DenseNet\t    'densenet121' 'densenet169' 'densenet201'\n",
    "# Inception\t    'inceptionv3' 'inceptionresnetv2'\n",
    "# MobileNet\t    'mobilenet' 'mobilenetv2'\n",
    "# Performance comparison for classification: https://github.com/qubvel/classification_models\n",
    "\n",
    "\"\"\"\n",
    "BACKBONE = 'resnet34'\n",
    "custom_weights_file = \"model_UNet-Resnet34_DSM_in01_95percOfTrain_8batch_100ep_dsm01proper.h5\" # None\n",
    "custom_weights_file = \"imagenet\"\n",
    "model = SiameseUnet(BACKBONE, encoder_weights=custom_weights_file, classes=3, activation='softmax', input_shape=(256, 256, 3))\n",
    "print(\"Model loaded:\")\n",
    "print(\"model.input\", model.input)\n",
    "print(\"model.output\", model.output)\n",
    "\"\"\"\n",
    "#model.summary()\n",
    "\n",
    "# Ps: there is posibility to change the code of additional models in similar manner to get FPN, Linknet and PSPNet\n",
    "# Ps2: some of these Siamese NN models end up with large amount of parameters ...\n",
    "#      if we don't have much data, we should perhaps freeze some of the layers of the encoder... \"encoder_freeze=False\"\n",
    "\n",
    "# Ps3: keras saves models into $ cd /home/<username>/.keras/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SiameseUnet(backbone_name='vgg16',\n",
    "         input_shape=(256, 256, 3),\n",
    "         classes=1,\n",
    "         activation='sigmoid',\n",
    "         encoder_weights=None,\n",
    "         encoder_freeze=False,\n",
    "         encoder_features='default',\n",
    "         decoder_block_type='upsampling',\n",
    "         decoder_filters=(256, 128, 64, 32, 16),\n",
    "         decoder_use_batchnorm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Generator Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import resnet\n",
    "\n",
    "from tensorflow.keras import applications\n",
    "\n",
    "from tensorflow.keras import layers,losses,optimizers,metrics,Model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "patch_size=32\n",
    "\n",
    "cnn=resnet.ResNet50(weights=None,input_shape=(patch_size,patch_size)+(3,),include_top=False)\n",
    "\n",
    "flatten=layers.Flatten()(cnn.output)\n",
    "\n",
    "dense_1=layers.Dense(512,activation='relu')(flatten)\n",
    "\n",
    "dense_1=layers.BatchNormalization()(dense_1)\n",
    "\n",
    "dense_2=layers.Dense(256,activation='relu')(dense_1)\n",
    "\n",
    "dense_2=layers.BatchNormalization()(dense_2)\n",
    "\n",
    "output=layers.Dense(256)(dense_2)\n",
    "\n",
    "embedding=Model(cnn.input,output,name='Embedding')\n",
    "\n",
    "embedding.summary()\n",
    "\n",
    "#for layer in cnn.layers:\n",
    "\n",
    "    \n",
    "    #if 'conv5_block3' in layer.name: #training just the last convolutional block\n",
    "        \n",
    "        #layer.trainable=True\n",
    "        \n",
    "    #else:\n",
    "        \n",
    "        #layer.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import vgg16\n",
    "\n",
    "from tensorflow.keras import layers, Model,losses, metrics, optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "patch_size=32\n",
    "\n",
    "cnn=vgg16.VGG16(weights='imagenet',input_shape=(patch_size,patch_size)+(3,),include_top=False)\n",
    "\n",
    "flatten=layers.Flatten()(cnn.output)\n",
    "\n",
    "dense_1=layers.Dense(512,activation='relu')(flatten)\n",
    "\n",
    "dense_1=layers.BatchNormalization()(dense_1)\n",
    "\n",
    "dense_2=layers.Dense(256,activation='relu')(dense_1)\n",
    "\n",
    "dense_2=layers.BatchNormalization()(dense_2)\n",
    "\n",
    "output=layers.Dense(256)(dense_2)\n",
    "\n",
    "embedding=Model(cnn.input,output,name='Embedding')\n",
    "\n",
    "#embedding.summary()\n",
    "\n",
    "for layer in cnn.layers:\n",
    "\n",
    "    \n",
    "    if 'block5' in layer.name: #training just the last convolutional block\n",
    "        \n",
    "        layer.trainable=True\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        layer.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import densenet\n",
    "\n",
    "from tensorflow.keras import layers, Model,losses, metrics, optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "patch_size=32\n",
    "\n",
    "cnn=densenet.DenseNet121(weights='imagenet',input_shape=(patch_size,patch_size)+(3,),include_top=False)\n",
    "\n",
    "flatten=layers.Flatten()(cnn.output)\n",
    "\n",
    "dense_1=layers.Dense(512,activation='relu')(flatten)\n",
    "\n",
    "dense_1=layers.BatchNormalization()(dense_1)\n",
    "\n",
    "dense_2=layers.Dense(256,activation='relu')(dense_1)\n",
    "\n",
    "dense_2=layers.BatchNormalization()(dense_2)\n",
    "\n",
    "output=layers.Dense(256)(dense_2)\n",
    "\n",
    "embedding=Model(cnn.input,output,name='Embedding')\n",
    "\n",
    "#embedding.summary()\n",
    "\n",
    "for layer in cnn.layers:\n",
    "\n",
    "    \n",
    "    if 'conv5_block16' in layer.name: #training just the last convolutional block\n",
    "        \n",
    "        layer.trainable=True\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        layer.trainable=False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method : Conventional CNN Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=256\n",
    "patch_size=32\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, GlobalAveragePooling2D, Dense\n",
    "\n",
    "embedding=Sequential([Conv2D(32,kernel_size=3,activation='relu',input_shape=(patch_size,patch_size,3)),\n",
    "                     \n",
    "                         Conv2D(32,kernel_size=3,activation='relu'),\n",
    "                            \n",
    "                         Conv2D(32,kernel_size=3,strides=2,padding='same',activation='relu'),\n",
    "                      \n",
    "                         Conv2D(64,kernel_size=3,activation='relu'),\n",
    "                      \n",
    "                         GlobalAveragePooling2D(),\n",
    "                      \n",
    "                         Dense(embedding_dim) \n",
    "\n",
    "])\n",
    "\n",
    "print(embedding.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Siamese Network Architecture With Triplets Of Anchor, Positive, and Negative Image Patches as Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import resnet\n",
    "\n",
    "from tensorflow.keras import applications\n",
    "\n",
    "from tensorflow.keras import layers,losses,optimizers,metrics,Model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "patch_size=32\n",
    "\n",
    "anchor_input=layers.Input(name='anchor',shape=(patch_size,patch_size)+(3,))\n",
    "\n",
    "positive_input=layers.Input(name='positive',shape=(patch_size,patch_size)+(3,))\n",
    "\n",
    "negative_input=layers.Input(name='negative',shape=(patch_size,patch_size)+(3,))\n",
    "\n",
    "embedding_anchor=embedding(anchor_input)\n",
    "embedding_positive=embedding(positive_input)\n",
    "embedding_negative=embedding(negative_input)\n",
    "\n",
    "#output=layers.concatenate([embedding_anchor,embedding_positive,embedding_negative])\n",
    "output=layers.concatenate([embedding_positive,embedding_negative])\n",
    "\n",
    "#model=Model([anchor_input,positive_input,negative_input],output)\n",
    "model=Model([positive_input,negative_input],output)\n",
    "\n",
    "#plot_model(model,to_file='D:/Nafiseh/flood_proposal/siamese_model_contrastive_loss_intensity_coh.png',show_shapes=True,show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Creating Triplets Of Anchor, Positive, and Negative Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def create_batch_data(train_resampled,label,batch_size):\n",
    "    \n",
    "        \n",
    "    def data_augmentation(data,image_count=1):\n",
    "\n",
    "        augmented_images=[]\n",
    "        \n",
    "        patch_size=32\n",
    "\n",
    "        datagen=ImageDataGenerator(horizontal_flip=True)\n",
    "\n",
    "        it=datagen.flow(np.expand_dims(data,axis=0),batch_size=1)\n",
    "\n",
    "        for i in range(image_count):\n",
    "    \n",
    "            augmented_images.append(np.squeeze(it.next(),axis=0))\n",
    "        \n",
    "        return(np.stack(augmented_images)) \n",
    "    \n",
    "    anchors,positives,negatives=np.zeros((batch_size,patch_size,patch_size,3)),np.zeros((batch_size,patch_size,patch_size,3)),np.zeros((batch_size,patch_size,patch_size,3))\n",
    "\n",
    "    positive_idx=np.squeeze(np.where(np.array(label)!=1)) #background \n",
    "\n",
    "        \n",
    "    negative_idx=np.squeeze(np.where(np.array(label)==1))\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        \n",
    "        \n",
    "        index=positive_idx[random.randint(0,len(positive_idx)-1)]\n",
    "\n",
    "        positive=train_resampled[index]  \n",
    "        \n",
    "        anchor=data_augmentation(positive)\n",
    "        \n",
    "        label_=label[index]\n",
    "        \n",
    "        negative=train_resampled[negative_idx[random.randint(0,len(negative_idx)-1)]]\n",
    "        \n",
    "        anchors[i],positives[i],negatives[i]=anchor,positive,negative \n",
    "    \n",
    "    return [anchors,positives,negatives]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def Triplet_Loss(margin, embedding_dim):\n",
    "    \n",
    "    def get_loss(output_true,output_pred):\n",
    "        \n",
    "        anchor_output=output_pred[:,:embedding_dim]\n",
    "        \n",
    "        positive_output=output_pred[:,embedding_dim:2*embedding_dim]\n",
    "        \n",
    "        negative_output=output_pred[:,2*embedding_dim:]\n",
    "        \n",
    "        dp=tf.reduce_sum(tf.square(anchor_output-positive_output),axis=1)\n",
    "        \n",
    "        dn=tf.reduce_sum(tf.square(anchor_output-negative_output),axis=1)\n",
    "        \n",
    "        return tf.maximum(dp-dn+margin,0)\n",
    "        \n",
    "    return get_loss    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Contrastive_Loss(margin,embedding_dim,tav): #tav:maximum acceptable distance between similar samples\n",
    "    \n",
    "    def get_loss(output_true,output_pred):\n",
    "        \n",
    "        input1=output_pred[:,:embedding_dim]\n",
    "        \n",
    "        input2=output_pred[:,embedding_dim:2*embedding_dim]\n",
    "        \n",
    "        d=tf.reduce_sum(tf.square(input1-input2))\n",
    "        \n",
    "        return(output_true*tf.maximum(margin-d,0)+(1-output_true)*tf.maximum(d-tav,0))  \n",
    "    \n",
    "    return get_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Double Margin Contrastive Loss (WDMCL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weighted_Double_Margin_Contrastive_Loss(embedding_dim,w1,w2 ,m1=0.9,m2=0.45):\n",
    "    \n",
    "    def get_loss(output_true,output_pred):\n",
    "\n",
    "        \n",
    "        input1=output_pred[:,:embedding_dim]\n",
    "    \n",
    "        input2=output_pred[:,embedding_dim:2*embedding_dim]\n",
    "        \n",
    "        d=tf.reduce_sum(tf.square(input1-input2))\n",
    "        \n",
    "        return(0.5*((w1*(1-output_true)*(tf.maximum(d-m1,0))**2)+(w2*output_true*(tf.maximum(m2-d,0))**2)))\n",
    "    \n",
    "    return(get_loss)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Data_Generator(train_resampled,label,batch_size,embedding_dim,mode):\n",
    "    \n",
    "    while True:\n",
    "    \n",
    "        x=create_batch_data(train_resampled,label,batch_size)\n",
    "        \n",
    "        if mode=='triplet':\n",
    "        \n",
    "            y=np.zeros((batch_size,3*embedding_dim))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            x=x[1:]\n",
    "            \n",
    "            y=np.zeros((batch_size,2*embedding_dim))\n",
    "        \n",
    "        yield x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply PCA transfrom on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def apply_pca_transform(data,n_components=3,patch_size=32):\n",
    "\n",
    "    def make_2d_feature_map_1d(data):\n",
    "\n",
    "        data_ravel=np.zeros((data.shape[0],data.shape[1]*data.shape[2],data.shape[3]))\n",
    "\n",
    "        for i in range(data.shape[0]):\n",
    "\n",
    "            for j in range(data.shape[3]):\n",
    "\n",
    "                 data_ravel[i,:,j]=np.ravel(data[i,:,:,j])\n",
    "\n",
    "        return(data_ravel)      \n",
    "\n",
    "\n",
    "    data_1d=make_2d_feature_map_1d(data)\n",
    "\n",
    "    data_transformed=[]\n",
    "    data_transformed_2d=[]\n",
    "\n",
    "    pca=PCA(n_components=3)\n",
    "\n",
    "    for k in range(data_1d.shape[0]):\n",
    "\n",
    "        data_transformed.append(pca.fit_transform(data_1d[k,:,:]))\n",
    "\n",
    "        data_transformed_2d.append(np.reshape(data_transformed[k],(patch_size,patch_size,n_components)))\n",
    "      \n",
    "    return(np.array(data_transformed_2d))\n",
    "\n",
    "train_resampled__=apply_pca_transform(train_resampled_)\n",
    "val_resampled__=apply_pca_transform(val_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting The Siamese Model and Setting Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "\n",
    "batch_size,embedding_dim, epochs=50, 256, 200\n",
    "\n",
    "lr_schedule=ExponentialDecay(0.0001,decay_rate=0.8,decay_steps=10000)\n",
    "\n",
    "#model.compile(loss=Triplet_Loss(margin=0.9, embedding_dim=embedding_dim),optimizer=Adam(learning_rate=lr_schedule))\n",
    "\n",
    "        \n",
    "w1=1/(len(train_label[train_label==0])) # weight for unchanged pixels\n",
    "        \n",
    "w2=1/(len(train_label[train_label==1])) # weight for changed pixels\n",
    "\n",
    "\n",
    "#Weighted_Double_Margin_Contrastive_Loss(embedding_dim,w1,w2,m1=0.9,m2=0.45)\n",
    "model.compile(loss=Contrastive_Loss(embedding_dim=embedding_dim,margin=0.01,tav=0.01),optimizer=Adam(learning_rate=lr_schedule))\n",
    "\n",
    "es=EarlyStopping(monitor='val_loss',patience=30,restore_best_weights=True)\n",
    "\n",
    "mch=ModelCheckpoint(filepath='D:/Nafiseh/flood_proposal/leverkhuzen_model.h5',save_best_only=True)\n",
    "\n",
    "val_data=create_batch_data(val_resampled__,val_label,val_resampled__.shape[0])\n",
    "\n",
    "val_data=val_data[1:] #omitting the anchor images\n",
    "\n",
    "\n",
    "history=model.fit(Data_Generator(train_resampled__,train_label,batch_size,embedding_dim,'contrastive'),steps_per_epoch=int(train_resampled__.shape[0]/batch_size),epochs=epochs,callbacks=[es,mch],validation_data=(val_data,val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "files=np.load('D:/Nafiseh/flood_proposal/leverkhuzen_saved_arrays.npz')\n",
    "\n",
    "train_resampled__,train_label,val_resampled__,val_data,val_label,embedding_dim=files['arr_0'],files['arr_1'],files['arr_2'],files['arr_3'],files['arr_4'],files['arr_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.ylabel('Tripplet Loss')\n",
    "\n",
    "plt.legend(['Train','Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/Nafiseh/flood_proposal/siamese_intensity_coh_leverkhuzen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#model=load_model('D:/Nafiseh/flood_proposal/siamese_intensity_coh_partial_TR_contrastive_loss_downsampling.h5',compile=False)\n",
    "model=load_model('D:/Nafiseh/flood_proposal/siamese_intensity_coh_leverkhuzen.h5',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('D:/Nafiseh/flood_proposal/training history_resnet50_intensity_coh_leverkhuzen.pckl', 'wb') as hist:\n",
    "    \n",
    "    pickle.dump(history.history,hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f=open('D:/Nafiseh/flood_proposal/training history_resnet50_intensity_coh_partial_TR_weighted_contrastive_loss.pckl','rb')\n",
    "\n",
    "history=pickle.load(f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "from tensorflow.keras import layers,Model,regularizers\n",
    "\n",
    "embedding_dim=256\n",
    "\n",
    "patch_size=32\n",
    "\n",
    "input_layer=layers.Input(shape=(embedding_dim,))\n",
    "\n",
    "flatten1=layers.Flatten()(input_layer)\n",
    "\n",
    "dense1=layers.Dense(64)(flatten1)\n",
    "\n",
    "LR1=LeakyReLU(alpha=0.1)(dense1)\n",
    "\n",
    "dense2=layers.Dense(64)(LR1)\n",
    "\n",
    "LR2=LeakyReLU(alpha=0.1)(dense2)\n",
    "\n",
    "drop1=layers.Dropout(0.1)(LR2)\n",
    "\n",
    "#dense3=layers.Dense(128,kernel_regularizer=regularizers.l1(0.0001))(drop1)\n",
    "\n",
    "#LR3=LeakyReLU(alpha=0.1)(dense3)\n",
    "\n",
    "#drop2=layers.Dropout(0.5)(LR3)\n",
    "\n",
    "#dense4=layers.Dense(64,kernel_regularizer=regularizers.l1(0.0001))(drop2)\n",
    "\n",
    "#LR4=LeakyReLU(alpha=0.1)(dense4)\n",
    "\n",
    "dense5=layers.Dense(32)(drop1)\n",
    "\n",
    "LR5=LeakyReLU(alpha=0.1)(dense5)\n",
    "\n",
    "prediction_layer=layers.Dense(2,activation='softmax')(LR5)\n",
    "\n",
    "model1=Model(input_layer,prediction_layer,name='prediction_model')\n",
    "\n",
    "train_data=create_batch_data(train_resampled__,train_label,train_resampled__.shape[0])\n",
    "\n",
    "train_data=train_data[1:] #omitting the anchor images\n",
    "\n",
    "##train_label_pos,train_label_neg=train_label[np.where(train_label==0)[0]],train_label[np.where(train_label==1)[0]]\n",
    "\n",
    "train_prediction=model.predict(train_data)\n",
    "\n",
    "val_prediction=model.predict(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting A Subset Of Train And Validation Data (Memory Issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset(data,label):\n",
    "\n",
    "    random.seed(1)\n",
    "\n",
    "    pos_idx,neg_idx=np.where(np.array(label)==1)[0],np.where(np.array(label)==0)[0]\n",
    "\n",
    "    pos_idx_subset,neg_idx_subset=random.sample(list(pos_idx),500),random.sample(list(neg_idx),500)\n",
    "\n",
    "    test_idx_subset=pos_idx_subset+neg_idx_subset\n",
    "\n",
    "    data_s=[data[i,:] for i in test_idx_subset]\n",
    "\n",
    "    label_s=[label[j] for j in test_idx_subset]\n",
    "    \n",
    "    return(np.stack(data_s),np.stack(label_s))\n",
    "\n",
    "#train_prediction_s,train_label_s=subset(train_prediction,train_label)\n",
    "\n",
    "#val_prediction_s,val_label_s=subset(val_prediction,val_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Senario 1: Difference Feature Vectors As Trainin Data to the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diff_pos=train_prediction[:,:embedding_dim]-train_prediction[:,embedding_dim:2*embedding_dim]\n",
    "\n",
    "train_diff_neg=train_prediction[:,:embedding_dim]-train_prediction[:,2*embedding_dim:]\n",
    "\n",
    "train_diff=np.concatenate((train_diff_pos,train_diff_neg),axis=0)\n",
    "\n",
    "train_diff_label=np.concatenate((np.zeros((len(train_diff_pos),)),np.ones((len(train_diff_neg),))),axis=0)\n",
    "\n",
    "val_diff_pos=val_prediction[:,:embedding_dim]-val_prediction[:,embedding_dim:2*embedding_dim]\n",
    "\n",
    "val_diff_neg=val_prediction[:,:embedding_dim]-val_prediction[:,2*embedding_dim:]\n",
    "\n",
    "val_diff=np.concatenate((val_diff_pos,val_diff_neg),axis=0)\n",
    "\n",
    "val_diff_label=np.concatenate((np.zeros((len(val_diff_pos),)),np.ones((len(val_diff_neg),))),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Senario 2: The Original Feature Vectors As Training Data to the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_f=train_prediction[:,:embedding_dim]\n",
    "pos_f=train_prediction[:,embedding_dim:2*embedding_dim]\n",
    "neg_f=train_prediction[:,2*embedding_dim:]\n",
    "train_pos,train_neg=np.concatenate((anchor_f,pos_f),axis=0),neg_f\n",
    "train_fv=np.concatenate((train_pos,train_neg),axis=0)\n",
    "\n",
    "pos_num=len(anchor_f)+len(pos_f)\n",
    "neg_num=len(neg_f)\n",
    "train_fv_label=np.concatenate((np.zeros((pos_num,)),np.ones((neg_num,))),axis=0)\n",
    "\n",
    "anchor_f_val,pos_f_val=val_prediction[:,:embedding_dim],val_prediction[:,embedding_dim:2*embedding_dim]\n",
    "neg_f_val=val_prediction[:,2*embedding_dim:]\n",
    "val_pos,val_neg=np.concatenate((anchor_f_val,pos_f_val),axis=0),neg_f_val\n",
    "val_fv=np.concatenate((val_pos,val_neg),axis=0)\n",
    "pos_num_val=len(anchor_f_val)+len(pos_f_val)\n",
    "neg_num_val=len(neg_f_val)\n",
    "val_fv_label=np.concatenate((np.zeros((pos_num_val,)),np.ones((neg_num_val,))),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_f=train_prediction[:,:embedding_dim]\n",
    "neg_f=train_prediction[:,embedding_dim:]\n",
    "train_fv=np.concatenate((pos_f,neg_f),axis=0)\n",
    "\n",
    "pos_num=len(pos_f)\n",
    "neg_num=len(neg_f)\n",
    "train_fv_label=np.concatenate((np.zeros((pos_num,)),np.ones((neg_num,))),axis=0)\n",
    "\n",
    "pos_f_val,neg_f_val=val_prediction[:,:embedding_dim],val_prediction[:,embedding_dim:]\n",
    "val_fv=np.concatenate((pos_f_val,neg_f_val),axis=0)\n",
    "pos_num_val=len(pos_f_val)\n",
    "neg_num_val=len(neg_f_val)\n",
    "val_fv_label=np.concatenate((np.zeros((pos_num_val,)),np.ones((neg_num_val,))),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adadelta\n",
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "#anchor_embedding_train,positive_embedding_train,negative_embedding_train=train_prediction[:,:256],train_prediction[:,256:2*256],train_prediction[:,2*256:3*256]\n",
    "\n",
    "#embedding_t,label_t=shuffle(np.concatenate((positive_embedding_train,negative_embedding_train),axis=0),np.concatenate((train_label_pos,train_label_neg),axis=0),random_state=2)\n",
    "\n",
    "lr_Schedule1=ExponentialDecay(0.0001,decay_rate=0.8,decay_steps=1000)\n",
    "\n",
    "es1=EarlyStopping(monitor='val_loss',min_delta=1e-4,patience=100,restore_best_weights=True)\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=lr_Schedule1),metrics=['accuracy'])\n",
    "\n",
    "history1=model1.fit(train_fv,to_categorical(train_fv_label,num_classes=2),batch_size=80, epochs=300,callbacks=[es1],validation_data=(val_fv,to_categorical(val_fv_label,num_classes=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(history1.history['loss'])\n",
    "\n",
    "plt.plot(history1.history['val_loss'])\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.ylabel('Binary Cross Entropy')\n",
    "\n",
    "plt.legend(['Train','Validation'])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(history1.history['accuracy'])\n",
    "\n",
    "plt.plot(history1.history['val_accuracy'])\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.legend(['Train','Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('D:/Nafiseh/flood_proposal/prediction_layer_model_intensity_coh_leverkhuzen.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "model1=load_model('D:/Nafiseh/flood_proposal/prediction_layer_model_intensity_coh_leverkhuzen.h5',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('D:/Nafiseh/flood_proposal/prediction_layer_model_intensity_coh_leverkhuzen.pckl','wb') as hist:\n",
    "    \n",
    "    pickle.dump(history1.history,hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "f=open('D:/Nafiseh/flood_proposal/prediction_layer_model_intensity_coh_partial_TR_weighted_contrastive_loss.pckl','rb')\n",
    "\n",
    "history1=pickle.load(f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Resnet50 From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "\n",
    "batch_size,embedding_dim, epochs=50, 256, 200\n",
    "es=EarlyStopping(monitor='val_loss',patience=50,restore_best_weights=True)\n",
    "\n",
    "lr_schedule=ExponentialDecay(0.0001,decay_rate=0.8,decay_steps=10000)\n",
    "\n",
    "model.compile(loss=Triplet_Loss(margin=0.9, embedding_dim=embedding_dim),optimizer=Adam(learning_rate=lr_schedule))\n",
    "\n",
    "es1=EarlyStopping(monitor='val_loss',min_delta=1e-4,patience=100,restore_best_weights=True)\n",
    "\n",
    "embedding.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=lr_Schedule),metrics=['accuracy'])\n",
    "\n",
    "history1=embedding.fit(train_resampled_,to_categorical(train_label,num_classes=2),batch_size=80, epochs=300,callbacks=[es1],validation_data=(val_resampled,to_categorical(val_label,num_classes=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_change_map(model,model1,train_data,preflood_resampled,test_resampled,label_test_new,embedding_dim):\n",
    "\n",
    "    test_label_p=[]\n",
    "\n",
    "    for i in range(len(test_resampled)):\n",
    "\n",
    "        #preflood_resampled_expanded=np.expand_dims(preflood_resampled[i],axis=2)\n",
    "        preflood_resampled_expanded=preflood_resampled\n",
    "        \n",
    "        embedding_input=np.expand_dims(np.concatenate((preflood_resampled_expanded[i],test_resampled[i]),axis=2),axis=0)\n",
    "        \n",
    "        if i>=len(train_data[0]): #end of the train data\n",
    "            \n",
    "            if i%len(train_data[0])==0:\n",
    "                \n",
    "               k=0 \n",
    "\n",
    "            train_anchor=np.expand_dims(train_data[0][k,:,:,:],axis=0)\n",
    "            \n",
    "            train_pos=np.expand_dims(train_data[1][k,:,:,:],axis=0)\n",
    "            \n",
    "            train_neg=np.expand_dims(train_data[2][k,:,:,:],axis=0)\n",
    "            \n",
    "            k+=1\n",
    "        \n",
    "        else:\n",
    "            \n",
    "\n",
    "            train_anchor=np.expand_dims(train_data[0][i,:,:,:],axis=0)\n",
    "\n",
    "            train_pos=np.expand_dims(train_data[1][i,:,:,:],axis=0)\n",
    "\n",
    "            train_neg=np.expand_dims(train_data[2][i,:,:,:],axis=0)\n",
    "\n",
    "        if label_test_new[i]==1: #change\n",
    "\n",
    "            embedding=model.predict([train_anchor,train_pos,embedding_input])\n",
    "            \n",
    "        elif label_test_new[i]==0: #no change\n",
    "\n",
    "            embedding=model.predict([train_anchor,embedding_input,train_neg])\n",
    "        \n",
    "        #prediction=np.expand_dims(prediction,axis=0)\n",
    "        \n",
    "        if label_test_new[i]==1: #change\n",
    "\n",
    "            test_label_p.append(np.argmax(model1.predict(embedding[:,2*embedding_dim:])))\n",
    "        \n",
    "        elif label_test_new[i]==0: #no change\n",
    "            \n",
    "            test_label_p.append(np.argmax(model1.predict(embedding[:,embedding_dim:2*embedding_dim])))\n",
    "            \n",
    "                            \n",
    "    return(test_label_p) \n",
    "\n",
    "intensity_array_vv_expanded=np.expand_dims(intensity_array_vv[:,:,0],axis=2)\n",
    "\n",
    "preflood_label=np.zeros((1500,1500))\n",
    "                            \n",
    "preflood_array_sample,preflood_label_pad=prepare_test_data(intensity_array_vv_expanded,preflood_label)\n",
    "\n",
    "preflood_resampled,_=resample_data(preflood_array_sample,preflood_label_pad,'preflood') \n",
    "\n",
    "test_label_p=create_change_map(model,model1,train_data,preflood_resampled,test_resampled,label_test_new,embedding_dim)                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_change_map(model,model1,train_data,test_resampled,label_test_new,embedding_dim):\n",
    "\n",
    "    test_label_p=[]\n",
    "    \n",
    "    #preflood_resampled_expanded=preflood_resampled\n",
    "\n",
    "    for i in range(len(test_resampled)):\n",
    "        \n",
    "        embedding_input=np.expand_dims(test_resampled[i],axis=0)\n",
    "        \n",
    "        if i>=len(train_data[0]): #end of the train data\n",
    "            \n",
    "            if i%len(train_data[0])==0:\n",
    "                \n",
    "               k=0 \n",
    "            \n",
    "            train_pos=np.expand_dims(train_data[0][k,:,:,:],axis=0)\n",
    "            \n",
    "            train_neg=np.expand_dims(train_data[1][k,:,:,:],axis=0)\n",
    "            \n",
    "            k+=1\n",
    "        \n",
    "        else:\n",
    "\n",
    "            train_pos=np.expand_dims(train_data[0][i,:,:,:],axis=0)\n",
    "\n",
    "            train_neg=np.expand_dims(train_data[1][i,:,:,:],axis=0)\n",
    "\n",
    "        if label_test_new[i]==1: #change\n",
    "\n",
    "            embedding=model.predict([train_pos,embedding_input])\n",
    "            \n",
    "        elif label_test_new[i]==0: #no change\n",
    "\n",
    "            embedding=model.predict([embedding_input,train_neg])\n",
    "        \n",
    "        #prediction=np.expand_dims(prediction,axis=0)\n",
    "        \n",
    "        if label_test_new[i]==1: #change\n",
    "\n",
    "            test_label_p.append(np.argmax(model1.predict(embedding[:,embedding_dim:])))\n",
    "        \n",
    "        elif label_test_new[i]==0: #no change\n",
    "            \n",
    "            test_label_p.append(np.argmax(model1.predict(embedding[:,:embedding_dim])))\n",
    "            \n",
    "                            \n",
    "    return(test_label_p) \n",
    "\n",
    "#index=[]\n",
    "\n",
    "#for i in range(0,int((len(test_sample)*2)/(col1+2))-1,2):\n",
    "    \n",
    "    #index.append(np.arange(i*(int((col1+2)/2)),(i+1)*(int((col1+2)/2))))\n",
    "    \n",
    "\n",
    "#f_index=np.ravel(index)  \n",
    "\n",
    "#f_index=np.delete(f_index,-1)\n",
    "\n",
    "#row1=stack_test_int_coh.shape[0]\n",
    "#col1=stack_test_int_coh.shape[1]\n",
    "\n",
    "#ts_array,lt_array=np.array(test_sample),np.array(label_test)\n",
    "\n",
    "#test_resampled,label_test_new=resample_data(test_sample[s],lt_array[s],'Test')\n",
    "\n",
    "chunks=1000\n",
    "\n",
    "test_label_pp=[]\n",
    "\n",
    "for s in range(0,len(test_sample),chunks):\n",
    "    \n",
    "    test_resampled,label_test_new=resample_data(test_sample[s:s+chunks],label_test[s:s+chunks],'Test')\n",
    "\n",
    "    test_resampled__=apply_pca_transform(test_resampled)\n",
    "\n",
    "#test_label_p=create_change_map(embedding,model1,train_data,test_resampled__,label_test_new,embedding_dim) #embedding do the same job as model\n",
    "\n",
    "    test_label_pp.append(create_change_map(model,model1,train_data,test_resampled__,label_test_new,embedding_dim)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.save('D:/Nafiseh/flood_proposal/leverkhuzen_change_labels_intensity_coh.npy',test_label_p)\n",
    "\n",
    "#test_label_p=np.load('D:/Nafiseh/flood_proposal/test_label_p_leverkhuzen_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows,ncols=992,2038\n",
    "\n",
    "change_map=np.reshape(np.concatenate((np.ravel(np.stack(test_label_pp[:-1])),test_label_pp[-1])),(nrows,ncols))\n",
    "\n",
    "plt.imshow(change_map,cmap=plt.cm.get_cmap('binary').reversed())\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('D:/Nafiseh/flood_proposal/leverkhuzen_change_labels_resnet_50_intensity_coh.npy', test_label_pp)\n",
    "#test_label_p=np.load('D:/Nafiseh/flood_proposal/gatineau_change_labels.npy')\n",
    "#test_label_p=np.load('D:/Nafiseh/flood_proposal/gatineau_change_labels_intensity_coh_partial_TR.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_rgb(image):\n",
    "    \n",
    "    for i in range(image.shape[2]):\n",
    "\n",
    "        image[:,:,i]=np.multiply((image[:,:,i]-np.min(image[:,:,i]))/(np.max(image[:,:,i])-np.min(image[:,:,i])),255)\n",
    "  \n",
    "    return(image)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing The Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal,osr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "path='D:/Nafiseh/flood_proposal'\n",
    "\n",
    "#stack_image_name='subset_0_of_S1A_IW_GRDH_1SDV_Cal_Spk_TC_Stack.tif'\n",
    "\n",
    "#stack_image_name='subset_1_of_S1A_IW_GRDH_1SDV_20190408T225218_20190507T23009_Cal_Spk_TC_Stack_2_subset.tif'\n",
    "\n",
    "stack_image_name='collocate_S1B_int_coh.tif'\n",
    "\n",
    "#Rapid_Eye_Image_name='0428_clip_3.tif'\n",
    "\n",
    "gt_name='hydrography_area_mask_leverkhuzen_clip.tif'\n",
    "\n",
    "gt=read_as_array(path,gt_name)\n",
    "\n",
    "#image_array=read_as_array(path,Rapid_Eye_Image_name)\n",
    "\n",
    "ds=gdal.Open(path+'/'+stack_image_name)\n",
    "\n",
    "#rapid_eye_ds=gdal.Open(path+'/'+Rapid_Eye_Image_name)\n",
    "\n",
    "ulx,xres,xskew,uly,yskew,yres=ds.GetGeoTransform()\n",
    "\n",
    "#uly_eye,yres_eye,yskew_eye,ulx_eye,xskew_eye,xres_eye=rapid_eye_ds.GetGeoTransform()\n",
    "\n",
    "#row,col=1501,1501\n",
    "\n",
    "#row,col=1379-1011+1,1055-505+1\n",
    "\n",
    "#row,col=301,301\n",
    "\n",
    "row,col=992, 2038\n",
    "\n",
    "#row_ul_new,col_ul_new=780,0\n",
    "row_ul_new,col_ul_new=0, 0\n",
    "\n",
    "#row_lr_new,col_lr_new=1080,300\n",
    "row_lr_new,col_lr_new=992, 2038\n",
    "\n",
    "\n",
    "gt=read_as_array(path,gt_name)\n",
    "\n",
    "\n",
    "def find_new_pixel_cor(row_new,col_new,ulx,uly,ulx_eye,uly_eye,xres,yres,xres_eye,yres_eye):\n",
    "\n",
    "    x_new=col_new*xres+ulx\n",
    "\n",
    "    y_new=row_new*yres+uly\n",
    "\n",
    "    utm_cor=utm.from_latlon(y_new,x_new)\n",
    "\n",
    "    y_new_utm,x_new_utm=utm_cor[0],utm_cor[1]\n",
    "\n",
    "    row_eye=np.int(np.floor((y_new_utm-uly_eye)/yres_eye))\n",
    "\n",
    "    col_eye=np.int(np.floor((x_new_utm-ulx_eye)/xres_eye))\n",
    "    \n",
    "    return(x_new,y_new,row_eye,col_eye)\n",
    "\n",
    "#x_new,y_new,row_ul_eye,col_ul_eye=find_new_pixel_cor(row_ul_new,col_ul_new,ulx,uly,ulx_eye,uly_eye,xres,yres,xres_eye,yres_eye)\n",
    "\n",
    "#_,_,row_lr_eye,col_lr_eye=find_new_pixel_cor(row_lr_new,col_lr_new,ulx,uly,ulx_eye,uly_eye,xres,yres,xres_eye,yres_eye)\n",
    "\n",
    "#RGB_image_array=image_array[:row_lr_eye+1,col_ul_eye:col_lr_eye+1,[2,1,0]]\n",
    "\n",
    "#ul_x_new,ul_y_new=x_new,y_new\n",
    "\n",
    "#BBOX=[ul_x_new, ul_x_new+xres*300, ul_y_new+yres*300, ul_y_new]\n",
    "BBOX=[6.9, 6.9+xres*2038, 50.983+yres*992, 51.072]\n",
    "\n",
    "#change_map=np.reshape(test_label_p,(row,col))\n",
    "\n",
    "orig_map=plt.cm.get_cmap('binary')\n",
    "\n",
    "reversed_map=orig_map.reversed()\n",
    "\n",
    "fig,ax=plt.subplots(1,2,figsize=(10,10))\n",
    "\n",
    "plt.setp(ax, xticks=np.round(np.arange(BBOX[0],BBOX[1],0.05),2), yticks=np.round(np.arange(BBOX[2],BBOX[3],0.06),3))\n",
    "\n",
    "ax[0].imshow(change_map, extent=BBOX, aspect='equal',cmap=reversed_map)\n",
    "\n",
    "#ax[0].set_title('Change Map \\n 07/05/2019',fontname='Times New Roman', fontweight='bold', fontsize=14)\n",
    "#ax[0].set_title('Change Map \\n 18/07/2019',fontname='Times New Roman', fontweight='bold', fontsize=14)\n",
    "ax[0].set_title('Flood Map',fontname='Times New Roman', fontweight='bold', fontsize=14)\n",
    "\n",
    "ax[1].imshow(gt,extent=BBOX, aspect='equal', cmap=reversed_map)\n",
    "\n",
    "ax[1].set_title('Ground Truth Mask',fontname='Times New Roman', fontweight='bold',fontsize=14)\n",
    "\n",
    "#ax[2].imshow(np.divide(RGB_image_array,(8,8,8)).astype('uint8'), extent=BBOX)\n",
    "\n",
    "#ax[2].set_title('Rapid Eye RGB image \\n 28/04/2019', fontname='Times New Roman', fontweight='bold',fontsize=14)\n",
    "\n",
    "fig.tight_layout(pad=3)\n",
    "\n",
    "#plt.savefig('D:/Nafiseh/flood_proposal/intensity_coh_contrastive_loss_resnet50_leverkhuzen.tif')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Change Map and Ground Truth Map as Geo Tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal, osr\n",
    "\n",
    "def Write_array_as_geotiff(array,ul_x_new,ul_y_new,raster_name):\n",
    "\n",
    "    ds=gdal.Open('D:/Nafiseh/flood_proposal/collocate_S1B_int_coh.tif')\n",
    "\n",
    "    ulx,xres,xskew,uly,yskew,yres=ds.GetGeoTransform()\n",
    "\n",
    "    geotransform=(ul_x_new, xres, xskew, ul_y_new, yskew, yres)\n",
    "\n",
    "    raster=gdal.GetDriverByName('GTiff').Create(raster_name,992,2038,1,gdal.GDT_Float32)\n",
    "\n",
    "    raster.SetGeoTransform(geotransform)\n",
    "\n",
    "    srs=osr.SpatialReference()\n",
    "\n",
    "    srs.ImportFromEPSG(4326)\n",
    "    \n",
    "    raster.GetRasterBand(1).WriteArray(array)\n",
    "    \n",
    "    raster.GetRasterBand(1).SetNoDataValue(0)\n",
    "    \n",
    "    raster.FlushCache() ##saves to disk\n",
    "    \n",
    "    raster=None\n",
    "    \n",
    "    ds=None\n",
    "\n",
    "\n",
    "Write_array_as_geotiff(change_map,0,0,'D:/Nafiseh/flood_proposal/CHM_contrastive_Loss_resnet50_intensity_coh.tif')\n",
    "\n",
    "#Write_array_as_geotiff(label_test_new_2D,ul_x_new,ul_y_new,'D:/Nafiseh/flood_proposal/Change_mask_07052019.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_resampled_s,label_test_s=subset(test_resampled,label_test_new)\n",
    "\n",
    "test_data=create_batch_data(test_resampled_s,label_test_s,test_resampled_s.shape[0])\n",
    "\n",
    "prediction=model.predict(test_data)\n",
    "\n",
    "diff_pr_pos=prediction[:,:embedding_dim]-prediction[:,embedding_dim:2*embedding_dim]\n",
    "\n",
    "diff_pr_neg=prediction[:,:embedding_dim]-prediction[:,2*embedding_dim:]\n",
    "\n",
    "diff_pr=np.concatenate((diff_pr_pos,diff_pr_neg),axis=0)\n",
    "\n",
    "#anchor_embedding_test,positive_embedding_test,negative_embedding_test=prediction[:,:256],prediction[:,256:2*256],prediction[:,2*256:3*256]\n",
    "\n",
    "test_label_p=np.argmax(model1.predict(diff_pr),axis=1)\n",
    "\n",
    "#dist_pos=np.square(np.expand_dims(np.sum(np.power(diff_pr_pos,2),axis=1),axis=1))\n",
    "#dist_neg=np.square(np.expand_dims(np.sum(np.power(diff_pr_neg,2),axis=1),axis=1))\n",
    "\n",
    "#diff_power=np.concatenate((dist_pos,dist_neg),axis=1)\n",
    "\n",
    "#test_label_p2=np.argmin(diff_power,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_resampled_s,label_test_s=subset(test_resampled,label_test_new)\n",
    "\n",
    "test_data=create_batch_data(test_resampled_s,label_test_s,test_resampled_s.shape[0])\n",
    "\n",
    "prediction=model.predict(test_data)\n",
    "\n",
    "pr_anchor,pr_pos,pr_neg=prediction[:,:embedding_dim],prediction[:,embedding_dim:2*embedding_dim],prediction[:,2*embedding_dim:]\n",
    "\n",
    "pr=np.concatenate((pr_anchor,pr_pos,pr_neg),axis=0)\n",
    "\n",
    "test_label_p=np.argmax(model1.predict(pr),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "change_map_r=zoom(change_map,[gt.shape[0]/change_map.shape[0],gt.shape[1]/change_map.shape[1]],order=1)\n",
    "\n",
    "sns.heatmap(confusion_matrix(np.ravel(gt),np.ravel(change_map_r)),annot=True,fmt='d')\n",
    "\n",
    "#plt.savefig('D:/Nafiseh/flood_proposal/confusion_matrix_contrastive_loss_resnet50_leverkhuzen.tif')\n",
    "\n",
    "text_file=open('D:/Nafiseh/flood_proposal/classification_report_contrastive_loss_resnet50_leverkhuzen.txt','a')\n",
    "\n",
    "print(classification_report(np.ravel(change_map_r),np.ravel(gt)))\n",
    "\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
